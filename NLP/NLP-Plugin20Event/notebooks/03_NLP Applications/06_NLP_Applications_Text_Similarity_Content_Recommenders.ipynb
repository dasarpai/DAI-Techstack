{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wGdpBKaHXuoc"
   },
   "source": [
    "# Movie Recommendations with Document Similarity\n",
    "\n",
    "Recommender systems are one of the popular and most adopted applications of machine learning. They are typically used to recommend entities to users and these entites can be anything like products, movies, services and so on. \n",
    "\n",
    "Popular examples of recommendations include,\n",
    "- Amazon suggesting products on its website\n",
    "- Amazon Prime, Netflix, Hotstar recommending movies\\shows\n",
    "- YouTube recommending videos to watch\n",
    "\n",
    "Typically recommender systems can be implemented in three ways:\n",
    "\n",
    "- Simple Rule-based Recommenders: Typically based on specific global metrics and thresholds like movie popularity, global ratings etc.\n",
    "- Content-based Recommenders: This is based on providing similar entities based on a specific entity of interest. Content metadata can be used here like movie descriptions, genre, cast, director and so on\n",
    "- Collaborative filtering Recommenders: Here we don't need metadata but we try to predict recommendations and ratings based on past ratings of different users and specific items.\n",
    "\n",
    "We will be building a movie recommendation system here where based on data\\metadata pertaining to different movies, we try and recommend similar movies of interest!\n",
    "\n",
    "![](https://i.imgur.com/c7Go7d3.png)\n",
    "\n",
    "Since our focus in not really recommendation engines but NLP, we will be leveraging the text-based metadata for each movie to try and recommend similar movies based on specific movies of interest. This falls under content-based recommenders. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S2lYDs1RjvRn"
   },
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "-U-mW8t5YDFH",
    "outputId": "bf0849c5-079d-44cf-a71a-de310210787a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textsearch\n",
      "  Downloading https://files.pythonhosted.org/packages/42/a8/03407021f9555043de5492a2bd7a35c56cc03c2510092b5ec018cae1bbf1/textsearch-0.0.17-py2.py3-none-any.whl\n",
      "Collecting Unidecode\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
      "\u001b[K     |████████████████████████████████| 245kB 7.9MB/s \n",
      "\u001b[?25hCollecting pyahocorasick\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/9f/f0d8e8850e12829eea2e778f1c90e3c53a9a799b7f412082a5d21cd19ae1/pyahocorasick-1.4.0.tar.gz (312kB)\n",
      "\u001b[K     |████████████████████████████████| 317kB 14.2MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
      "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.0-cp36-cp36m-linux_x86_64.whl size=81702 sha256=806fc3ab02550f97e873a75ee295eb4acc7e8b73d1ad761dcd80d0de3dd91064\n",
      "  Stored in directory: /root/.cache/pip/wheels/0a/90/61/87a55f5b459792fbb2b7ba6b31721b06ff5cf6bde541b40994\n",
      "Successfully built pyahocorasick\n",
      "Installing collected packages: Unidecode, pyahocorasick, textsearch\n",
      "Successfully installed Unidecode-1.1.1 pyahocorasick-1.4.0 textsearch-0.0.17\n",
      "Collecting contractions\n",
      "  Downloading https://files.pythonhosted.org/packages/85/41/c3dfd5feb91a8d587ed1a59f553f07c05f95ad4e5d00ab78702fbf8fe48a/contractions-0.0.24-py2.py3-none-any.whl\n",
      "Requirement already satisfied: textsearch in /usr/local/lib/python3.6/dist-packages (from contractions) (0.0.17)\n",
      "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.4.0)\n",
      "Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.1.1)\n",
      "Installing collected packages: contractions\n",
      "Successfully installed contractions-0.0.24\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install textsearch\n",
    "!pip install contractions\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7_de4c8pjvRr"
   },
   "source": [
    "# Load and View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "ctP-qx30YUyC",
    "outputId": "ba2083d4-0322-43bc-b7bb-ee8ee28c7575"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4803 entries, 0 to 4802\n",
      "Data columns (total 20 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   budget                4803 non-null   int64  \n",
      " 1   genres                4803 non-null   object \n",
      " 2   homepage              1712 non-null   object \n",
      " 3   id                    4803 non-null   int64  \n",
      " 4   keywords              4803 non-null   object \n",
      " 5   original_language     4803 non-null   object \n",
      " 6   original_title        4803 non-null   object \n",
      " 7   overview              4800 non-null   object \n",
      " 8   popularity            4803 non-null   float64\n",
      " 9   production_companies  4803 non-null   object \n",
      " 10  production_countries  4803 non-null   object \n",
      " 11  release_date          4802 non-null   object \n",
      " 12  revenue               4803 non-null   int64  \n",
      " 13  runtime               4801 non-null   float64\n",
      " 14  spoken_languages      4803 non-null   object \n",
      " 15  status                4803 non-null   object \n",
      " 16  tagline               3959 non-null   object \n",
      " 17  title                 4803 non-null   object \n",
      " 18  vote_average          4803 non-null   float64\n",
      " 19  vote_count            4803 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(13)\n",
      "memory usage: 750.6+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://github.com/dipanjanS/nlp_workshop_dhs18/raw/master/Unit%2010%20-%20Project%208%20-%20Movie%20Recommendations%20with%20Document%20Similarity/tmdb_5000_movies.csv.gz', compression='gzip')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 702
    },
    "colab_type": "code",
    "id": "frQbM_zrZC2D",
    "outputId": "8b46b999-021c-4374-e4e8-255c6a1d73c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.avatarmovie.com/</td>\n",
       "      <td>19995</td>\n",
       "      <td>[{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>[{\"name\": \"Ingenious Film Partners\", \"id\": 289...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2009-12-10</td>\n",
       "      <td>2787965087</td>\n",
       "      <td>162.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Enter the World of Pandora.</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300000000</td>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...</td>\n",
       "      <td>http://disney.go.com/disneypictures/pirates/</td>\n",
       "      <td>285</td>\n",
       "      <td>[{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...</td>\n",
       "      <td>en</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>Captain Barbossa, long believed to be dead, ha...</td>\n",
       "      <td>139.082615</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2007-05-19</td>\n",
       "      <td>961000000</td>\n",
       "      <td>169.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>At the end of the world, the adventure begins.</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.sonypictures.com/movies/spectre/</td>\n",
       "      <td>206647</td>\n",
       "      <td>[{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...</td>\n",
       "      <td>en</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>A cryptic message from Bond’s past sends him o...</td>\n",
       "      <td>107.376788</td>\n",
       "      <td>[{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...</td>\n",
       "      <td>[{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...</td>\n",
       "      <td>2015-10-26</td>\n",
       "      <td>880674609</td>\n",
       "      <td>148.0</td>\n",
       "      <td>[{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...</td>\n",
       "      <td>Released</td>\n",
       "      <td>A Plan No One Escapes</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...</td>\n",
       "      <td>http://www.thedarkknightrises.com/</td>\n",
       "      <td>49026</td>\n",
       "      <td>[{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...</td>\n",
       "      <td>en</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>Following the death of District Attorney Harve...</td>\n",
       "      <td>112.312950</td>\n",
       "      <td>[{\"name\": \"Legendary Pictures\", \"id\": 923}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2012-07-16</td>\n",
       "      <td>1084939099</td>\n",
       "      <td>165.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The Legend Ends</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>260000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://movies.disney.com/john-carter</td>\n",
       "      <td>49529</td>\n",
       "      <td>[{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>John Carter is a war-weary, former military ca...</td>\n",
       "      <td>43.926995</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}]</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2012-03-07</td>\n",
       "      <td>284139100</td>\n",
       "      <td>132.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Lost in our world, found in another.</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      budget  ... vote_count\n",
       "0  237000000  ...      11800\n",
       "1  300000000  ...       4500\n",
       "2  245000000  ...       4466\n",
       "3  250000000  ...       9106\n",
       "4  260000000  ...       2124\n",
       "\n",
       "[5 rows x 20 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "2lURVWdjZGHL",
    "outputId": "341937af-3a75-4fc9-b8f5-051bd5d48115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4800 entries, 546 to 4553\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   title        4800 non-null   object \n",
      " 1   tagline      4800 non-null   object \n",
      " 2   overview     4800 non-null   object \n",
      " 3   popularity   4800 non-null   float64\n",
      " 4   description  4800 non-null   object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 225.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df[['title', 'tagline', 'overview', 'popularity']]\n",
    "df.tagline.fillna('', inplace=True)\n",
    "df['description'] = df['tagline'].map(str) + ' ' + df['overview']\n",
    "df.dropna(inplace=True)\n",
    "df = df.sort_values(by=['popularity'], ascending=False)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "hfwvf3UgZJK6",
    "outputId": "224b2622-664a-4ca2-8bea-2d017d990b74"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tagline</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>Minions</td>\n",
       "      <td>Before Gru, they had a history of bad bosses</td>\n",
       "      <td>Minions Stuart, Kevin and Bob are recruited by...</td>\n",
       "      <td>875.581305</td>\n",
       "      <td>Before Gru, they had a history of bad bosses M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Interstellar</td>\n",
       "      <td>Mankind was born on Earth. It was never meant ...</td>\n",
       "      <td>Interstellar chronicles the adventures of a gr...</td>\n",
       "      <td>724.247784</td>\n",
       "      <td>Mankind was born on Earth. It was never meant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>Deadpool</td>\n",
       "      <td>Witness the beginning of a happy ending</td>\n",
       "      <td>Deadpool tells the origin story of former Spec...</td>\n",
       "      <td>514.569956</td>\n",
       "      <td>Witness the beginning of a happy ending Deadpo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Guardians of the Galaxy</td>\n",
       "      <td>All heroes start somewhere.</td>\n",
       "      <td>Light years from Earth, 26 years after being a...</td>\n",
       "      <td>481.098624</td>\n",
       "      <td>All heroes start somewhere. Light years from E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Mad Max: Fury Road</td>\n",
       "      <td>What a Lovely Day.</td>\n",
       "      <td>An apocalyptic story set in the furthest reach...</td>\n",
       "      <td>434.278564</td>\n",
       "      <td>What a Lovely Day. An apocalyptic story set in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title  ...                                        description\n",
       "546                  Minions  ...  Before Gru, they had a history of bad bosses M...\n",
       "95              Interstellar  ...  Mankind was born on Earth. It was never meant ...\n",
       "788                 Deadpool  ...  Witness the beginning of a happy ending Deadpo...\n",
       "94   Guardians of the Galaxy  ...  All heroes start somewhere. Light years from E...\n",
       "127       Mad Max: Fury Road  ...  What a Lovely Day. An apocalyptic story set in...\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wDHsF6qZWNv"
   },
   "source": [
    "# Build a Movie Recommender System\n",
    "\n",
    "Here you will build your own movie recommender system. We will use the following pipeline:\n",
    "- Text pre-processing\n",
    "- Feature Engineering\n",
    "- Document Similarity Computation\n",
    "- Find top similar movies\n",
    "- Build a movie recommendation function\n",
    "\n",
    "\n",
    "## Document Similarity\n",
    "\n",
    "Recommendations are about understanding the underlying features which make us favour one choice over the other. Similarity between items(in this case movies) is one way to understanding why we choose one movie over another. There are different ways to calculate similarity between two items. One of the most widely used measures is __cosine similarity__ which we have already used in the previous unit.\n",
    "\n",
    "### Cosine Similarity\n",
    "\n",
    "Cosine Similarity is used to calculate a numeric score to denote the similarity between two text documents. Mathematically, it is defined as follows:\n",
    "\n",
    "$$ cosine(x,y) = \\frac{x. y^\\intercal}{||x||.||y||} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BjLTJDE9ZXSj",
    "outputId": "2643ed1b-92c6-466e-b9ae-81eeba4be39e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4800"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import contractions\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    doc = contractions.fix(doc)\n",
    "    # tokenize document\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    #filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)\n",
    "\n",
    "norm_corpus = normalize_corpus(list(df['description']))\n",
    "len(norm_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uNiwar7saOuj"
   },
   "source": [
    "## Extract TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NZkWolSnaRkd",
    "outputId": "c26d1f42-92c3-408e-ec49-b1096d2f505c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 20468)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf = TfidfVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "tfidf_matrix = tf.fit_transform(norm_corpus)\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PIyXn448aXnt"
   },
   "source": [
    "## Compute Pairwise Document Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "dKYgrUc4aUHm",
    "outputId": "4efb9bc1-135e-4824-e7db-073251006c46"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>4760</th>\n",
       "      <th>4761</th>\n",
       "      <th>4762</th>\n",
       "      <th>4763</th>\n",
       "      <th>4764</th>\n",
       "      <th>4765</th>\n",
       "      <th>4766</th>\n",
       "      <th>4767</th>\n",
       "      <th>4768</th>\n",
       "      <th>4769</th>\n",
       "      <th>4770</th>\n",
       "      <th>4771</th>\n",
       "      <th>4772</th>\n",
       "      <th>4773</th>\n",
       "      <th>4774</th>\n",
       "      <th>4775</th>\n",
       "      <th>4776</th>\n",
       "      <th>4777</th>\n",
       "      <th>4778</th>\n",
       "      <th>4779</th>\n",
       "      <th>4780</th>\n",
       "      <th>4781</th>\n",
       "      <th>4782</th>\n",
       "      <th>4783</th>\n",
       "      <th>4784</th>\n",
       "      <th>4785</th>\n",
       "      <th>4786</th>\n",
       "      <th>4787</th>\n",
       "      <th>4788</th>\n",
       "      <th>4789</th>\n",
       "      <th>4790</th>\n",
       "      <th>4791</th>\n",
       "      <th>4792</th>\n",
       "      <th>4793</th>\n",
       "      <th>4794</th>\n",
       "      <th>4795</th>\n",
       "      <th>4796</th>\n",
       "      <th>4797</th>\n",
       "      <th>4798</th>\n",
       "      <th>4799</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006070</td>\n",
       "      <td>0.008067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025531</td>\n",
       "      <td>0.008554</td>\n",
       "      <td>0.018111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007439</td>\n",
       "      <td>0.010454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008190</td>\n",
       "      <td>0.008365</td>\n",
       "      <td>0.010035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050976</td>\n",
       "      <td>0.006502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.167573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009191</td>\n",
       "      <td>0.053475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009711</td>\n",
       "      <td>0.006508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034092</td>\n",
       "      <td>0.018754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017839</td>\n",
       "      <td>0.007967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008885</td>\n",
       "      <td>0.009432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011407</td>\n",
       "      <td>0.011409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024326</td>\n",
       "      <td>0.005471</td>\n",
       "      <td>0.018038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005099</td>\n",
       "      <td>0.004985</td>\n",
       "      <td>0.004705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003672</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>0.030998</td>\n",
       "      <td>0.006959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019548</td>\n",
       "      <td>0.020365</td>\n",
       "      <td>0.009213</td>\n",
       "      <td>0.028467</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.004198</td>\n",
       "      <td>0.006311</td>\n",
       "      <td>0.015154</td>\n",
       "      <td>0.012698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020597</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.008604</td>\n",
       "      <td>0.012782</td>\n",
       "      <td>0.015353</td>\n",
       "      <td>0.006259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006903</td>\n",
       "      <td>0.005023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027126</td>\n",
       "      <td>0.009340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.017839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012232</td>\n",
       "      <td>0.017893</td>\n",
       "      <td>0.043639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009324</td>\n",
       "      <td>0.022995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014029</td>\n",
       "      <td>0.030561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056761</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060846</td>\n",
       "      <td>0.025035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036237</td>\n",
       "      <td>0.030516</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00607</td>\n",
       "      <td>0.007967</td>\n",
       "      <td>0.017176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036611</td>\n",
       "      <td>0.023879</td>\n",
       "      <td>0.014421</td>\n",
       "      <td>0.012316</td>\n",
       "      <td>0.019834</td>\n",
       "      <td>0.008170</td>\n",
       "      <td>0.004308</td>\n",
       "      <td>0.025459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008907</td>\n",
       "      <td>0.023736</td>\n",
       "      <td>0.011341</td>\n",
       "      <td>0.003009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028521</td>\n",
       "      <td>0.016018</td>\n",
       "      <td>0.011311</td>\n",
       "      <td>0.016912</td>\n",
       "      <td>0.022974</td>\n",
       "      <td>0.054142</td>\n",
       "      <td>0.013767</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.005416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>0.015097</td>\n",
       "      <td>0.030759</td>\n",
       "      <td>0.013663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027018</td>\n",
       "      <td>0.012025</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022327</td>\n",
       "      <td>0.007051</td>\n",
       "      <td>0.038014</td>\n",
       "      <td>0.011783</td>\n",
       "      <td>0.018612</td>\n",
       "      <td>0.021468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008650</td>\n",
       "      <td>0.009499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022056</td>\n",
       "      <td>0.019659</td>\n",
       "      <td>0.036850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076022</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>0.043469</td>\n",
       "      <td>0.011464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2     ...      4797      4798      4799\n",
       "0  1.00000  0.000000  0.000000  ...  0.000000  0.000000  0.009646\n",
       "1  0.00000  1.000000  0.000000  ...  0.000000  0.000000  0.007963\n",
       "2  0.00000  0.000000  1.000000  ...  0.000000  0.027126  0.009340\n",
       "3  0.00000  0.017839  0.000000  ...  0.000000  0.000000  0.000000\n",
       "4  0.00607  0.007967  0.017176  ...  0.004515  0.043469  0.011464\n",
       "\n",
       "[5 rows x 4800 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "doc_sim = cosine_similarity(tfidf_matrix)\n",
    "doc_sim_df = pd.DataFrame(doc_sim)\n",
    "doc_sim_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h08MqvY9adgt"
   },
   "source": [
    "## Get List of Movie Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "rWr6lgqTaZsJ",
    "outputId": "e71ed347-2667-431b-bd3c-9c343b704da5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Minions', 'Interstellar', 'Deadpool', ..., 'Penitentiary',\n",
       "        'Alien Zone', 'America Is Still the Place'], dtype=object), (4800,))"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_list = df['title'].values\n",
    "movies_list, movies_list.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "69SKx3ZTaftu"
   },
   "source": [
    "## Find Top Similar Movies for a Sample Movie\n",
    "\n",
    "Let's take __Minions__ the most popular movie the the dataframe above and try and find the most similar movies which can be recommended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JT3tw7Wka6B0"
   },
   "source": [
    "#### Find movie ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MmAUpmxWa-Kv",
    "outputId": "ebfad8e3-77f1-4004-ca8c-ce1be801cb69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_idx = np.where(movies_list == 'Minions')[0][0]\n",
    "movie_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2IO3VhLka_vi"
   },
   "source": [
    "#### Get movie similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "Shbop-mDbDSS",
    "outputId": "7bc72ee0-3cd6-4595-8b4c-2e4232e1ee6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "       0.00964634])"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_similarities = doc_sim_df.iloc[movie_idx].values\n",
    "movie_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cjMx8FqtbE4O"
   },
   "source": [
    "#### Get top 5 similar movie IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AgmQgy8QbHDF",
    "outputId": "c00ee209-a607-4e0b-9348-30bb77681bd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 33,  60, 737, 490, 298])"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_movie_idxs = np.argsort(-movie_similarities)[1:6]\n",
    "similar_movie_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n7Fzp3qcbJv3"
   },
   "source": [
    "#### Get top 5 similar movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "h4o7WpNlbNlT",
    "outputId": "8ca9f814-165d-4fb9-ff72-31fcc096cc56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Despicable Me 2', 'Despicable Me',\n",
       "       'Teenage Mutant Ninja Turtles: Out of the Shadows', 'Superman',\n",
       "       'Rise of the Guardians'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_movies = movies_list[similar_movie_idxs]\n",
    "similar_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f5lpIbnMcnOx"
   },
   "source": [
    "### Build a movie recommender function to recommend top 5 similar movies for any movie \n",
    "\n",
    "The movie title, movie title list and document similarity matrix dataframe will be given as inputs to the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OOL8nLbacpXq"
   },
   "outputs": [],
   "source": [
    "def movie_recommender(movie_title, movies=movies_list, doc_sims=doc_sim_df):\n",
    "    # find movie id\n",
    "    movie_idx = np.where(movies == movie_title)[0][0]\n",
    "    # get movie similarities\n",
    "    movie_similarities = doc_sims.iloc[movie_idx].values\n",
    "    # get top 5 similar movie IDs\n",
    "    similar_movie_idxs = np.argsort(-movie_similarities)[1:6]\n",
    "    # get top 5 movies\n",
    "    similar_movies = movies[similar_movie_idxs]\n",
    "    # return the top 5 movies\n",
    "    return similar_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U4t4wBWwceFA"
   },
   "source": [
    "# Get popular Movie Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5V4EpMgAbPYY"
   },
   "outputs": [],
   "source": [
    "popular_movies = ['Minions', 'Interstellar', 'Deadpool', 'Jurassic World', 'Pirates of the Caribbean: The Curse of the Black Pearl',\n",
    "              'Dawn of the Planet of the Apes', 'The Hunger Games: Mockingjay - Part 1', 'Terminator Genisys', \n",
    "              'Captain America: Civil War', 'The Dark Knight', 'The Martian', 'Batman v Superman: Dawn of Justice', \n",
    "              'Pulp Fiction', 'The Godfather', 'The Shawshank Redemption', 'The Lord of the Rings: The Fellowship of the Ring',  \n",
    "              'Harry Potter and the Chamber of Secrets', 'Star Wars', 'The Hobbit: The Battle of the Five Armies',\n",
    "              'Iron Man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "N1ky8g-Ichp6",
    "outputId": "17575641-1b5f-4ae8-800a-5b65be5808e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Minions\n",
      "Top 5 recommended Movies: ['Despicable Me 2' 'Despicable Me'\n",
      " 'Teenage Mutant Ninja Turtles: Out of the Shadows' 'Superman'\n",
      " 'Rise of the Guardians']\n",
      "\n",
      "Movie: Interstellar\n",
      "Top 5 recommended Movies: ['Gattaca' 'Space Pirate Captain Harlock' 'Space Cowboys'\n",
      " 'Starship Troopers' 'Final Destination 2']\n",
      "\n",
      "Movie: Deadpool\n",
      "Top 5 recommended Movies: ['Silent Trigger' 'Underworld: Evolution' 'Bronson' 'Shaft' 'Don Jon']\n",
      "\n",
      "Movie: Jurassic World\n",
      "Top 5 recommended Movies: ['Jurassic Park' 'The Lost World: Jurassic Park'\n",
      " \"National Lampoon's Vacation\" 'The Nut Job' 'Vacation']\n",
      "\n",
      "Movie: Pirates of the Caribbean: The Curse of the Black Pearl\n",
      "Top 5 recommended Movies: [\"Pirates of the Caribbean: Dead Man's Chest\"\n",
      " 'Pirates of the Caribbean: On Stranger Tides' 'The Pirate'\n",
      " 'The Pirates! In an Adventure with Scientists!' 'Joyful Noise']\n",
      "\n",
      "Movie: Dawn of the Planet of the Apes\n",
      "Top 5 recommended Movies: ['Battle for the Planet of the Apes' 'Groove' 'The Other End of the Line'\n",
      " 'Chicago Overcoat' 'Definitely, Maybe']\n",
      "\n",
      "Movie: The Hunger Games: Mockingjay - Part 1\n",
      "Top 5 recommended Movies: ['The Hunger Games: Catching Fire' 'The Hunger Games: Mockingjay - Part 2'\n",
      " 'John Carter' 'For Greater Glory - The True Story of Cristiada'\n",
      " 'The Proposition']\n",
      "\n",
      "Movie: Terminator Genisys\n",
      "Top 5 recommended Movies: ['Terminator 2: Judgment Day' 'Terminator Salvation'\n",
      " 'Terminator 3: Rise of the Machines' 'Mad Max'\n",
      " 'X-Men: Days of Future Past']\n",
      "\n",
      "Movie: Captain America: Civil War\n",
      "Top 5 recommended Movies: ['Captain America: The Winter Soldier' 'This Means War'\n",
      " 'Avengers: Age of Ultron' 'Iron Man 2' 'Escape from Tomorrow']\n",
      "\n",
      "Movie: The Dark Knight\n",
      "Top 5 recommended Movies: ['The Dark Knight Rises' 'Batman Forever' 'Batman Returns'\n",
      " 'Batman: The Dark Knight Returns, Part 2' 'JFK']\n",
      "\n",
      "Movie: The Martian\n",
      "Top 5 recommended Movies: ['The Last Days on Mars' 'Swept Away' 'Alive' 'All Is Lost' 'Red Planet']\n",
      "\n",
      "Movie: Batman v Superman: Dawn of Justice\n",
      "Top 5 recommended Movies: ['Batman Returns' 'The Punisher' 'Defendor'\n",
      " 'Batman: The Dark Knight Returns, Part 2' 'Nowhere to Run']\n",
      "\n",
      "Movie: Pulp Fiction\n",
      "Top 5 recommended Movies: ['Sliding Doors' 'You Kill Me' 'New York Stories' 'Timecrimes'\n",
      " 'All or Nothing']\n",
      "\n",
      "Movie: The Godfather\n",
      "Top 5 recommended Movies: ['The Godfather: Part II' 'Blood Ties' 'Made' 'Lords of London'\n",
      " 'Easy Money']\n",
      "\n",
      "Movie: The Shawshank Redemption\n",
      "Top 5 recommended Movies: ['Civil Brand' 'Les Misérables' 'The Chorus' 'Prison' 'Fortress']\n",
      "\n",
      "Movie: The Lord of the Rings: The Fellowship of the Ring\n",
      "Top 5 recommended Movies: ['The Lord of the Rings: The Two Towers'\n",
      " 'The Hobbit: The Desolation of Smaug'\n",
      " 'The Lord of the Rings: The Return of the King'\n",
      " \"What's the Worst That Could Happen?\" 'The Hobbit: An Unexpected Journey']\n",
      "\n",
      "Movie: Harry Potter and the Chamber of Secrets\n",
      "Top 5 recommended Movies: ['Harry Potter and the Prisoner of Azkaban'\n",
      " 'Harry Potter and the Goblet of Fire'\n",
      " 'Harry Potter and the Order of the Phoenix'\n",
      " 'Harry Potter and the Half-Blood Prince'\n",
      " \"Harry Potter and the Philosopher's Stone\"]\n",
      "\n",
      "Movie: Star Wars\n",
      "Top 5 recommended Movies: ['The Empire Strikes Back' 'Return of the Jedi' 'Shrek the Third'\n",
      " 'The Ice Pirates' 'The Tale of Despereaux']\n",
      "\n",
      "Movie: The Hobbit: The Battle of the Five Armies\n",
      "Top 5 recommended Movies: ['The Hobbit: The Desolation of Smaug' 'The Hobbit: An Unexpected Journey'\n",
      " \"Dragon Nest: Warriors' Dawn\"\n",
      " 'A Funny Thing Happened on the Way to the Forum' 'X-Men: Apocalypse']\n",
      "\n",
      "Movie: Iron Man\n",
      "Top 5 recommended Movies: ['Iron Man 2' 'Avengers: Age of Ultron' 'Hostage' 'Iron Man 3'\n",
      " 'Baahubali: The Beginning']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for movie in popular_movies:\n",
    "    print('Movie:', movie)\n",
    "    print('Top 5 recommended Movies:', movie_recommender(movie_title=movie, movies=movies_list, doc_sims=doc_sim_df))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z7PezLIojvSQ"
   },
   "source": [
    "# Movie Recommendation with Embeddings\n",
    "\n",
    "We used count based normalized features in the previous section. Can we use word embeddings and then compute movie similarity? We definitely can! Here we will use the FastText model and train it on our corpus.\n",
    "\n",
    "The FastText model was first introduced by Facebook in 2016 as an extension and supposedly improvement of the vanilla Word2Vec model. Based on the original paper titled ‘Enriching Word Vectors with Subword Information’ by Mikolov et al. which is an excellent read to gain an in-depth understanding of how this model works. Overall, FastText is a framework for learning word representations and also performing robust, fast and accurate text classification. The framework is open-sourced by Facebook on GitHub and claims to have the following.\n",
    "- Recent state-of-the-art English word vectors.\n",
    "- Word vectors for 157 languages trained on Wikipedia and Crawl.\n",
    "- Models for language identification and various supervised tasks.\n",
    "\n",
    "Though I haven’t implemented this model from scratch, based on the research paper, following is what I learnt about how the model works. In general, predictive models like the Word2Vec model typically considers each word as a distinct entity (e.g. `where`) and generates a dense embedding for the word. However this poses to be a serious limitation with languages having massive vocabularies and many rare words which may not occur a lot in different corpora. The Word2Vec model typically ignores the morphological structure of each word and considers a word as a single entity. The FastText model considers each word as a Bag of Character n-grams. This is also called as a subword model in the paper.\n",
    "\n",
    "We add special boundary symbols < and > at the beginning and end of words. This enables us to distinguish prefixes and suffixes from other character sequences. We also include the word w itself in the set of its n-grams, to learn a representation for each word (in addition to its character n-grams). Taking the word `where` and n=3 (tri-grams) as an example, it will be represented by the character n-grams: `<wh, whe, her, ere, re>` and the special sequence `<where>` representing the whole word. Note that the sequence , corresponding to the word `<her>` is different from the tri-gram `her` from the word `where`.\n",
    "\n",
    "Here we leverage `gensim` to build our embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V-uTK-ovctOw"
   },
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "tokenized_docs = [doc.split() for doc in norm_corpus]\n",
    "ft_model = FastText(tokenized_docs, size=300, window=30, min_count=2, workers=4, sg=1, iter=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nyx0yxV_jvSS"
   },
   "source": [
    "# Generate document level embeddings\n",
    "\n",
    "Word embedding models give us an embedding for each word, how can we use it for downstream ML\\DL tasks? one way is to flatten it or use sequential models. A simpler approach is to average all word embeddings for words in a document and generate a fixed-length document level emebdding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Te0xZdxFfXkK"
   },
   "outputs": [],
   "source": [
    "def averaged_word2vec_vectorizer(corpus, model, num_features):\n",
    "    vocabulary = set(model.wv.index2word)\n",
    "    \n",
    "    def average_word_vectors(words, model, vocabulary, num_features):\n",
    "        feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
    "        nwords = 0.\n",
    "        \n",
    "        for word in words:\n",
    "            if word in vocabulary: \n",
    "                nwords = nwords + 1.\n",
    "                feature_vector = np.add(feature_vector, model.wv[word])\n",
    "        if nwords:\n",
    "            feature_vector = np.divide(feature_vector, nwords)\n",
    "\n",
    "        return feature_vector\n",
    "\n",
    "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
    "                    for tokenized_sentence in corpus]\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WhYLq48zf9mq",
    "outputId": "6f031d80-cb26-4cd6-8ccc-dc3997260ba3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 300)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vecs_ft = averaged_word2vec_vectorizer(tokenized_docs, ft_model, 300)\n",
    "doc_vecs_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "taowG-dijvSV"
   },
   "source": [
    "# Get Movie Recommendations\n",
    "\n",
    "We will leverage cosine similarity again to generate recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "-RQYRBoChXLb",
    "outputId": "ae31782e-8312-45af-931e-c89fa0d15ddc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>4760</th>\n",
       "      <th>4761</th>\n",
       "      <th>4762</th>\n",
       "      <th>4763</th>\n",
       "      <th>4764</th>\n",
       "      <th>4765</th>\n",
       "      <th>4766</th>\n",
       "      <th>4767</th>\n",
       "      <th>4768</th>\n",
       "      <th>4769</th>\n",
       "      <th>4770</th>\n",
       "      <th>4771</th>\n",
       "      <th>4772</th>\n",
       "      <th>4773</th>\n",
       "      <th>4774</th>\n",
       "      <th>4775</th>\n",
       "      <th>4776</th>\n",
       "      <th>4777</th>\n",
       "      <th>4778</th>\n",
       "      <th>4779</th>\n",
       "      <th>4780</th>\n",
       "      <th>4781</th>\n",
       "      <th>4782</th>\n",
       "      <th>4783</th>\n",
       "      <th>4784</th>\n",
       "      <th>4785</th>\n",
       "      <th>4786</th>\n",
       "      <th>4787</th>\n",
       "      <th>4788</th>\n",
       "      <th>4789</th>\n",
       "      <th>4790</th>\n",
       "      <th>4791</th>\n",
       "      <th>4792</th>\n",
       "      <th>4793</th>\n",
       "      <th>4794</th>\n",
       "      <th>4795</th>\n",
       "      <th>4796</th>\n",
       "      <th>4797</th>\n",
       "      <th>4798</th>\n",
       "      <th>4799</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.511302</td>\n",
       "      <td>0.502442</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.528635</td>\n",
       "      <td>0.500080</td>\n",
       "      <td>0.493744</td>\n",
       "      <td>0.441682</td>\n",
       "      <td>0.418781</td>\n",
       "      <td>0.491868</td>\n",
       "      <td>0.523494</td>\n",
       "      <td>0.550925</td>\n",
       "      <td>0.519979</td>\n",
       "      <td>0.515370</td>\n",
       "      <td>0.500810</td>\n",
       "      <td>0.496880</td>\n",
       "      <td>0.499552</td>\n",
       "      <td>0.555010</td>\n",
       "      <td>0.481648</td>\n",
       "      <td>0.470528</td>\n",
       "      <td>0.476052</td>\n",
       "      <td>0.550860</td>\n",
       "      <td>0.549369</td>\n",
       "      <td>0.536346</td>\n",
       "      <td>0.551250</td>\n",
       "      <td>0.488230</td>\n",
       "      <td>0.493090</td>\n",
       "      <td>0.530481</td>\n",
       "      <td>0.508521</td>\n",
       "      <td>0.546005</td>\n",
       "      <td>0.492862</td>\n",
       "      <td>0.532359</td>\n",
       "      <td>0.517098</td>\n",
       "      <td>0.661127</td>\n",
       "      <td>0.496009</td>\n",
       "      <td>0.546881</td>\n",
       "      <td>0.577576</td>\n",
       "      <td>0.457160</td>\n",
       "      <td>0.512193</td>\n",
       "      <td>0.576422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559431</td>\n",
       "      <td>0.586633</td>\n",
       "      <td>0.484196</td>\n",
       "      <td>0.529011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516703</td>\n",
       "      <td>0.420489</td>\n",
       "      <td>0.543944</td>\n",
       "      <td>0.426553</td>\n",
       "      <td>0.488764</td>\n",
       "      <td>0.509261</td>\n",
       "      <td>0.571376</td>\n",
       "      <td>0.443529</td>\n",
       "      <td>0.521385</td>\n",
       "      <td>0.433221</td>\n",
       "      <td>0.470482</td>\n",
       "      <td>0.490767</td>\n",
       "      <td>0.427758</td>\n",
       "      <td>0.467651</td>\n",
       "      <td>0.497448</td>\n",
       "      <td>0.527395</td>\n",
       "      <td>0.478380</td>\n",
       "      <td>0.355710</td>\n",
       "      <td>0.570109</td>\n",
       "      <td>0.506890</td>\n",
       "      <td>0.490687</td>\n",
       "      <td>0.529436</td>\n",
       "      <td>0.532387</td>\n",
       "      <td>0.496729</td>\n",
       "      <td>0.540363</td>\n",
       "      <td>0.557306</td>\n",
       "      <td>0.465027</td>\n",
       "      <td>0.593647</td>\n",
       "      <td>0.475393</td>\n",
       "      <td>0.520352</td>\n",
       "      <td>0.488696</td>\n",
       "      <td>0.537164</td>\n",
       "      <td>0.473445</td>\n",
       "      <td>0.536729</td>\n",
       "      <td>0.571257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.511302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.566714</td>\n",
       "      <td>0.549979</td>\n",
       "      <td>0.600978</td>\n",
       "      <td>0.521167</td>\n",
       "      <td>0.511621</td>\n",
       "      <td>0.594962</td>\n",
       "      <td>0.501481</td>\n",
       "      <td>0.528362</td>\n",
       "      <td>0.565163</td>\n",
       "      <td>0.582697</td>\n",
       "      <td>0.519681</td>\n",
       "      <td>0.508839</td>\n",
       "      <td>0.644944</td>\n",
       "      <td>0.459322</td>\n",
       "      <td>0.534871</td>\n",
       "      <td>0.577091</td>\n",
       "      <td>0.593148</td>\n",
       "      <td>0.504588</td>\n",
       "      <td>0.478492</td>\n",
       "      <td>0.568275</td>\n",
       "      <td>0.565592</td>\n",
       "      <td>0.517751</td>\n",
       "      <td>0.566722</td>\n",
       "      <td>0.504249</td>\n",
       "      <td>0.480088</td>\n",
       "      <td>0.572968</td>\n",
       "      <td>0.590939</td>\n",
       "      <td>0.610731</td>\n",
       "      <td>0.546957</td>\n",
       "      <td>0.558976</td>\n",
       "      <td>0.535946</td>\n",
       "      <td>0.477216</td>\n",
       "      <td>0.518014</td>\n",
       "      <td>0.592132</td>\n",
       "      <td>0.605179</td>\n",
       "      <td>0.464539</td>\n",
       "      <td>0.518335</td>\n",
       "      <td>0.609088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555567</td>\n",
       "      <td>0.586026</td>\n",
       "      <td>0.637444</td>\n",
       "      <td>0.543856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.567128</td>\n",
       "      <td>0.477251</td>\n",
       "      <td>0.569315</td>\n",
       "      <td>0.458893</td>\n",
       "      <td>0.536986</td>\n",
       "      <td>0.661497</td>\n",
       "      <td>0.577950</td>\n",
       "      <td>0.530159</td>\n",
       "      <td>0.567745</td>\n",
       "      <td>0.503204</td>\n",
       "      <td>0.447067</td>\n",
       "      <td>0.525203</td>\n",
       "      <td>0.471118</td>\n",
       "      <td>0.438648</td>\n",
       "      <td>0.516966</td>\n",
       "      <td>0.543324</td>\n",
       "      <td>0.560992</td>\n",
       "      <td>0.284606</td>\n",
       "      <td>0.522790</td>\n",
       "      <td>0.507424</td>\n",
       "      <td>0.487365</td>\n",
       "      <td>0.549090</td>\n",
       "      <td>0.575551</td>\n",
       "      <td>0.444088</td>\n",
       "      <td>0.488083</td>\n",
       "      <td>0.555832</td>\n",
       "      <td>0.494100</td>\n",
       "      <td>0.549236</td>\n",
       "      <td>0.475745</td>\n",
       "      <td>0.572120</td>\n",
       "      <td>0.492701</td>\n",
       "      <td>0.499046</td>\n",
       "      <td>0.506980</td>\n",
       "      <td>0.516795</td>\n",
       "      <td>0.572526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.502442</td>\n",
       "      <td>0.566714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.580393</td>\n",
       "      <td>0.589644</td>\n",
       "      <td>0.465381</td>\n",
       "      <td>0.497831</td>\n",
       "      <td>0.503388</td>\n",
       "      <td>0.534154</td>\n",
       "      <td>0.597208</td>\n",
       "      <td>0.563798</td>\n",
       "      <td>0.555063</td>\n",
       "      <td>0.515747</td>\n",
       "      <td>0.520897</td>\n",
       "      <td>0.560326</td>\n",
       "      <td>0.500669</td>\n",
       "      <td>0.569174</td>\n",
       "      <td>0.565353</td>\n",
       "      <td>0.536763</td>\n",
       "      <td>0.524209</td>\n",
       "      <td>0.474242</td>\n",
       "      <td>0.551723</td>\n",
       "      <td>0.574235</td>\n",
       "      <td>0.507742</td>\n",
       "      <td>0.559261</td>\n",
       "      <td>0.565257</td>\n",
       "      <td>0.463235</td>\n",
       "      <td>0.540280</td>\n",
       "      <td>0.544818</td>\n",
       "      <td>0.545302</td>\n",
       "      <td>0.563054</td>\n",
       "      <td>0.547144</td>\n",
       "      <td>0.543766</td>\n",
       "      <td>0.511543</td>\n",
       "      <td>0.571780</td>\n",
       "      <td>0.551673</td>\n",
       "      <td>0.555399</td>\n",
       "      <td>0.493871</td>\n",
       "      <td>0.578986</td>\n",
       "      <td>0.578136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.584595</td>\n",
       "      <td>0.544019</td>\n",
       "      <td>0.539711</td>\n",
       "      <td>0.498183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.518403</td>\n",
       "      <td>0.480600</td>\n",
       "      <td>0.571368</td>\n",
       "      <td>0.448289</td>\n",
       "      <td>0.554197</td>\n",
       "      <td>0.525684</td>\n",
       "      <td>0.581976</td>\n",
       "      <td>0.543566</td>\n",
       "      <td>0.545722</td>\n",
       "      <td>0.502141</td>\n",
       "      <td>0.462451</td>\n",
       "      <td>0.500899</td>\n",
       "      <td>0.504048</td>\n",
       "      <td>0.464067</td>\n",
       "      <td>0.480231</td>\n",
       "      <td>0.532025</td>\n",
       "      <td>0.536557</td>\n",
       "      <td>0.322640</td>\n",
       "      <td>0.542589</td>\n",
       "      <td>0.467284</td>\n",
       "      <td>0.466563</td>\n",
       "      <td>0.532118</td>\n",
       "      <td>0.547782</td>\n",
       "      <td>0.532992</td>\n",
       "      <td>0.542077</td>\n",
       "      <td>0.535158</td>\n",
       "      <td>0.535976</td>\n",
       "      <td>0.559784</td>\n",
       "      <td>0.486695</td>\n",
       "      <td>0.569468</td>\n",
       "      <td>0.524609</td>\n",
       "      <td>0.540876</td>\n",
       "      <td>0.531957</td>\n",
       "      <td>0.538434</td>\n",
       "      <td>0.542209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.549979</td>\n",
       "      <td>0.580393</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.601361</td>\n",
       "      <td>0.511930</td>\n",
       "      <td>0.471471</td>\n",
       "      <td>0.509934</td>\n",
       "      <td>0.492516</td>\n",
       "      <td>0.549093</td>\n",
       "      <td>0.548344</td>\n",
       "      <td>0.544424</td>\n",
       "      <td>0.498291</td>\n",
       "      <td>0.496964</td>\n",
       "      <td>0.572130</td>\n",
       "      <td>0.539825</td>\n",
       "      <td>0.540828</td>\n",
       "      <td>0.568344</td>\n",
       "      <td>0.504659</td>\n",
       "      <td>0.479900</td>\n",
       "      <td>0.473418</td>\n",
       "      <td>0.559258</td>\n",
       "      <td>0.570248</td>\n",
       "      <td>0.546384</td>\n",
       "      <td>0.591945</td>\n",
       "      <td>0.527202</td>\n",
       "      <td>0.442076</td>\n",
       "      <td>0.498183</td>\n",
       "      <td>0.476570</td>\n",
       "      <td>0.594568</td>\n",
       "      <td>0.499362</td>\n",
       "      <td>0.519452</td>\n",
       "      <td>0.528875</td>\n",
       "      <td>0.489922</td>\n",
       "      <td>0.495400</td>\n",
       "      <td>0.576544</td>\n",
       "      <td>0.622815</td>\n",
       "      <td>0.493807</td>\n",
       "      <td>0.534753</td>\n",
       "      <td>0.582049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510245</td>\n",
       "      <td>0.493633</td>\n",
       "      <td>0.520590</td>\n",
       "      <td>0.574458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503971</td>\n",
       "      <td>0.433858</td>\n",
       "      <td>0.554588</td>\n",
       "      <td>0.388063</td>\n",
       "      <td>0.519127</td>\n",
       "      <td>0.501825</td>\n",
       "      <td>0.542972</td>\n",
       "      <td>0.463595</td>\n",
       "      <td>0.530355</td>\n",
       "      <td>0.540010</td>\n",
       "      <td>0.446047</td>\n",
       "      <td>0.530681</td>\n",
       "      <td>0.496039</td>\n",
       "      <td>0.456804</td>\n",
       "      <td>0.562271</td>\n",
       "      <td>0.573115</td>\n",
       "      <td>0.502811</td>\n",
       "      <td>0.339796</td>\n",
       "      <td>0.543681</td>\n",
       "      <td>0.518335</td>\n",
       "      <td>0.477205</td>\n",
       "      <td>0.543971</td>\n",
       "      <td>0.600424</td>\n",
       "      <td>0.473617</td>\n",
       "      <td>0.524142</td>\n",
       "      <td>0.528456</td>\n",
       "      <td>0.581796</td>\n",
       "      <td>0.586280</td>\n",
       "      <td>0.492864</td>\n",
       "      <td>0.542407</td>\n",
       "      <td>0.531190</td>\n",
       "      <td>0.556593</td>\n",
       "      <td>0.498145</td>\n",
       "      <td>0.520941</td>\n",
       "      <td>0.538543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.528635</td>\n",
       "      <td>0.600978</td>\n",
       "      <td>0.589644</td>\n",
       "      <td>0.601361</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.578956</td>\n",
       "      <td>0.566108</td>\n",
       "      <td>0.684347</td>\n",
       "      <td>0.553761</td>\n",
       "      <td>0.545996</td>\n",
       "      <td>0.581761</td>\n",
       "      <td>0.634236</td>\n",
       "      <td>0.548112</td>\n",
       "      <td>0.576508</td>\n",
       "      <td>0.659951</td>\n",
       "      <td>0.559980</td>\n",
       "      <td>0.649455</td>\n",
       "      <td>0.612791</td>\n",
       "      <td>0.629575</td>\n",
       "      <td>0.575166</td>\n",
       "      <td>0.534134</td>\n",
       "      <td>0.612667</td>\n",
       "      <td>0.634250</td>\n",
       "      <td>0.592310</td>\n",
       "      <td>0.585712</td>\n",
       "      <td>0.521354</td>\n",
       "      <td>0.497366</td>\n",
       "      <td>0.617343</td>\n",
       "      <td>0.607622</td>\n",
       "      <td>0.659886</td>\n",
       "      <td>0.577232</td>\n",
       "      <td>0.631399</td>\n",
       "      <td>0.632367</td>\n",
       "      <td>0.559407</td>\n",
       "      <td>0.632903</td>\n",
       "      <td>0.606909</td>\n",
       "      <td>0.646658</td>\n",
       "      <td>0.551887</td>\n",
       "      <td>0.642283</td>\n",
       "      <td>0.611706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.595560</td>\n",
       "      <td>0.573215</td>\n",
       "      <td>0.646287</td>\n",
       "      <td>0.574188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.567009</td>\n",
       "      <td>0.540580</td>\n",
       "      <td>0.604099</td>\n",
       "      <td>0.456235</td>\n",
       "      <td>0.540456</td>\n",
       "      <td>0.637040</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.575581</td>\n",
       "      <td>0.588643</td>\n",
       "      <td>0.581220</td>\n",
       "      <td>0.522797</td>\n",
       "      <td>0.589999</td>\n",
       "      <td>0.559315</td>\n",
       "      <td>0.579137</td>\n",
       "      <td>0.598613</td>\n",
       "      <td>0.598693</td>\n",
       "      <td>0.580735</td>\n",
       "      <td>0.345960</td>\n",
       "      <td>0.612576</td>\n",
       "      <td>0.585203</td>\n",
       "      <td>0.556811</td>\n",
       "      <td>0.617860</td>\n",
       "      <td>0.573168</td>\n",
       "      <td>0.580257</td>\n",
       "      <td>0.547453</td>\n",
       "      <td>0.632275</td>\n",
       "      <td>0.626026</td>\n",
       "      <td>0.632767</td>\n",
       "      <td>0.468015</td>\n",
       "      <td>0.612453</td>\n",
       "      <td>0.543448</td>\n",
       "      <td>0.641255</td>\n",
       "      <td>0.575424</td>\n",
       "      <td>0.644583</td>\n",
       "      <td>0.631314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2     ...      4797      4798      4799\n",
       "0  1.000000  0.511302  0.502442  ...  0.473445  0.536729  0.571257\n",
       "1  0.511302  1.000000  0.566714  ...  0.506980  0.516795  0.572526\n",
       "2  0.502442  0.566714  1.000000  ...  0.531957  0.538434  0.542209\n",
       "3  0.507692  0.549979  0.580393  ...  0.498145  0.520941  0.538543\n",
       "4  0.528635  0.600978  0.589644  ...  0.575424  0.644583  0.631314\n",
       "\n",
       "[5 rows x 4800 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sim = cosine_similarity(doc_vecs_ft)\n",
    "doc_sim_df = pd.DataFrame(doc_sim)\n",
    "doc_sim_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "SM-fGDVvgcuX",
    "outputId": "6d8bd84c-94cb-41a0-c925-caec1bf0f971"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Minions\n",
      "Top 5 recommended Movies: ['Despicable Me' 'Time Bandits'\n",
      " 'Rise of the Entrepreneur: The Search for a Better Way'\n",
      " 'Austin Powers: The Spy Who Shagged Me' 'Despicable Me 2']\n",
      "\n",
      "Movie: Interstellar\n",
      "Top 5 recommended Movies: ['Gattaca' 'Prometheus' 'Sea Rex 3D: Journey to a Prehistoric World'\n",
      " 'Space Cowboys' 'The Cave']\n",
      "\n",
      "Movie: Deadpool\n",
      "Top 5 recommended Movies: ['Fantastic Four' 'Banshee Chapter' 'Enough' 'The Hunted' 'Spider-Man 3']\n",
      "\n",
      "Movie: Jurassic World\n",
      "Top 5 recommended Movies: ['Jurassic Park' 'The Lost World: Jurassic Park' 'Jurassic Park III'\n",
      " \"National Lampoon's Vacation\" 'Walking With Dinosaurs']\n",
      "\n",
      "Movie: Pirates of the Caribbean: The Curse of the Black Pearl\n",
      "Top 5 recommended Movies: ['Pirates of the Caribbean: On Stranger Tides'\n",
      " 'American Ninja 2: The Confrontation'\n",
      " 'The Pirates! In an Adventure with Scientists!'\n",
      " \"Pirates of the Caribbean: Dead Man's Chest\" 'The Pirate']\n",
      "\n",
      "Movie: Dawn of the Planet of the Apes\n",
      "Top 5 recommended Movies: ['Battle for the Planet of the Apes' 'Conquest of the Planet of the Apes'\n",
      " 'Hard to Be a God' 'Planet of the Apes' 'Beneath the Planet of the Apes']\n",
      "\n",
      "Movie: The Hunger Games: Mockingjay - Part 1\n",
      "Top 5 recommended Movies: ['The Hunger Games: Catching Fire' 'The Hunger Games: Mockingjay - Part 2'\n",
      " 'The Hunger Games' 'Thor: The Dark World' 'White House Down']\n",
      "\n",
      "Movie: Terminator Genisys\n",
      "Top 5 recommended Movies: ['Terminator 2: Judgment Day' 'X-Men: Days of Future Past'\n",
      " 'Terminator 3: Rise of the Machines' 'Terminator Salvation'\n",
      " 'The Terminator']\n",
      "\n",
      "Movie: Captain America: Civil War\n",
      "Top 5 recommended Movies: ['Captain America: The Winter Soldier' 'Iron Man 2'\n",
      " 'Avengers: Age of Ultron' 'Star Trek Into Darkness' 'Divergent']\n",
      "\n",
      "Movie: The Dark Knight\n",
      "Top 5 recommended Movies: ['The Dark Knight Rises' 'Batman Forever' 'Batman' 'Batman Returns'\n",
      " 'Batman Begins']\n",
      "\n",
      "Movie: The Martian\n",
      "Top 5 recommended Movies: ['Battleship' 'Red Planet' 'Star Trek IV: The Voyage Home' 'Alien'\n",
      " 'Sanctum']\n",
      "\n",
      "Movie: Batman v Superman: Dawn of Justice\n",
      "Top 5 recommended Movies: ['Batman: The Dark Knight Returns, Part 2' 'Defendor' 'Batman Returns'\n",
      " 'Batman' 'The Dark Knight Rises']\n",
      "\n",
      "Movie: Pulp Fiction\n",
      "Top 5 recommended Movies: ['Locker 13' 'Sliding Doors' 'Urbania' '11:14' 'All or Nothing']\n",
      "\n",
      "Movie: The Godfather\n",
      "Top 5 recommended Movies: ['The Godfather: Part II' 'The Godfather: Part III' 'Loose Cannons'\n",
      " 'The Jerky Boys' 'Blood Ties']\n",
      "\n",
      "Movie: The Shawshank Redemption\n",
      "Top 5 recommended Movies: ['Civil Brand' 'Escape Plan' 'Prison' 'Get Hard' 'Bridge of Spies']\n",
      "\n",
      "Movie: The Lord of the Rings: The Fellowship of the Ring\n",
      "Top 5 recommended Movies: ['The Hobbit: An Unexpected Journey'\n",
      " 'The Lord of the Rings: The Two Towers'\n",
      " 'The Lord of the Rings: The Return of the King'\n",
      " 'The Hobbit: The Desolation of Smaug'\n",
      " 'The Hobbit: The Battle of the Five Armies']\n",
      "\n",
      "Movie: Harry Potter and the Chamber of Secrets\n",
      "Top 5 recommended Movies: ['Harry Potter and the Prisoner of Azkaban'\n",
      " 'Harry Potter and the Goblet of Fire'\n",
      " 'Harry Potter and the Order of the Phoenix'\n",
      " 'Harry Potter and the Half-Blood Prince'\n",
      " \"Harry Potter and the Philosopher's Stone\"]\n",
      "\n",
      "Movie: Star Wars\n",
      "Top 5 recommended Movies: ['The Empire Strikes Back' 'Return of the Jedi'\n",
      " 'Star Wars: Episode III - Revenge of the Sith'\n",
      " 'Star Wars: Episode II - Attack of the Clones' 'The Ice Pirates']\n",
      "\n",
      "Movie: The Hobbit: The Battle of the Five Armies\n",
      "Top 5 recommended Movies: ['The Hobbit: The Desolation of Smaug' 'The Hobbit: An Unexpected Journey'\n",
      " \"Dragon Nest: Warriors' Dawn\" '300: Rise of an Empire'\n",
      " 'Battle for the Planet of the Apes']\n",
      "\n",
      "Movie: Iron Man\n",
      "Top 5 recommended Movies: ['Iron Man 2' 'Avengers: Age of Ultron' 'Steel' 'Ant-Man' 'Batman Begins']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for movie in popular_movies:\n",
    "    print('Movie:', movie)\n",
    "    print('Top 5 recommended Movies:', movie_recommender(movie_title=movie, movies=movies_list, doc_sims=doc_sim_df))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "06-NLP Applications - Text Similarity Content Recommenders.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
