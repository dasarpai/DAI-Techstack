{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-iKMVCis12aq"
   },
   "source": [
    "# Topic Modeling on Research Papers\n",
    "\n",
    "We will do an interesting exercise here—build topic models on past research papers\n",
    "from the very popular NIPS conference (now known as the NeurIPS conference). The\n",
    "late professor Sam Roweis compiled an excellent collection of NIPS Conference Papers\n",
    "from Volume 1 – 12, which you can find at https://cs.nyu.edu/~roweis/data.html.\n",
    "An interesting fact is that he obtained this by massaging the OCR’d data from NIPS\n",
    "1-12, which was actually the pre-electronic submission era. Yann LeCun made the data\n",
    "available. There is an even more updated dataset available up to NIPS 17 at http://\n",
    "ai.stanford.edu/~gal/data.html. However, that dataset is in the form of a MAT file, so\n",
    "you might need to do some additional preprocessing before working on it in Python.\n",
    "\n",
    "\n",
    "# The Main Objective\n",
    "\n",
    "Considering our discussion so far, our main objective is pretty simple. Given a whole\n",
    "bunch of conference research papers, can we identify some key themes or topics from\n",
    "these papers by leveraging unsupervised learning? We do not have the liberty of labeled\n",
    "categories telling us what the major themes of every research paper are. Besides that, we\n",
    "are dealing with text data extracted using OCR (optical character recognition). Hence,\n",
    "you can expect misspelled words, words with characters missing, and so on, which\n",
    "makes our problem even more challenging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bsTqya546U6q"
   },
   "source": [
    "# Download Data and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "BJaNFsqQ6KGt",
    "outputId": "b60afcc2-507c-472a-e77f-4e919cd2d797"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-27 15:55:33--  https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz\n",
      "Resolving cs.nyu.edu (cs.nyu.edu)... 128.122.49.30\n",
      "Connecting to cs.nyu.edu (cs.nyu.edu)|128.122.49.30|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12851423 (12M) [application/x-gzip]\n",
      "Saving to: ‘nips12raw_str602.tgz’\n",
      "\n",
      "nips12raw_str602.tg 100%[===================>]  12.26M  21.4MB/s    in 0.6s    \n",
      "\n",
      "2020-05-27 15:55:34 (21.4 MB/s) - ‘nips12raw_str602.tgz’ saved [12851423/12851423]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz\n",
    "!tar -xzf nips12raw_str602.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "C36S18zo8w3b",
    "outputId": "6a27870f-b355-42c6-abd3-d09d2c8582c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "oHpf-YxR6XuW",
    "outputId": "28535ea1-37f0-4442-b4e7-01f99d81032d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nips01', 'nips04', 'nips08', 'nips00', 'RAW_DATA_NOTES', 'MATLAB_NOTES', 'nips03', 'nips02', 'orig', 'README_yann', 'nips10', 'nips07', 'nips12', 'nips09', 'nips11', 'nips05', 'idx', 'nips06']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = 'nipstxt/'\n",
    "print(os.listdir(DATA_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y20UiwtA6pAg"
   },
   "source": [
    "# Load NIPS Research Papers Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "D3G8nUsJ6h7V",
    "outputId": "959efe9b-651c-46f9-e7d7-b3474ed38040"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1740"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = [\"nips{0:02}\".format(i) for i in range(0,13)]\n",
    "# Read all texts into a list.\n",
    "papers = []\n",
    "for folder in folders:\n",
    "    file_names = os.listdir(DATA_PATH + folder)\n",
    "    for file_name in file_names:\n",
    "        with open(DATA_PATH + folder + '/' + file_name, encoding='utf-8', errors='ignore', mode='r+') as f:\n",
    "            data = f.read()\n",
    "        papers.append(data)\n",
    "len(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "id": "JaTh1Jll6kx9",
    "outputId": "0beea0d3-e6e8-4584-f8f7-b89210e1bc64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804 \n",
      "INTRODUCTION TO A SYSTEM FOR IMPLEMENTING NEURAL NET \n",
      "CONNECTIONS ON SIMD ARCHITECTURES \n",
      "Sherryl Tomboulian \n",
      "Institute for Computer Applications in Science and Engineering \n",
      "NASA Langley Research Center, Hampton VA 23665 \n",
      "ABSTRACT \n",
      "Neural networks have attracted much interest recently, and using parallel \n",
      "architectures to simulate neural networks is a natural and necessary applica- \n",
      "tion. The SIMD model of parallel computation is chosen, because systems of \n",
      "this type can be built with large numbers of processing elements. However, \n",
      "such systems are not naturally suited to generalized communication. A method \n",
      "is proposed that allows an implementation of neural network connections on \n",
      "massively parallel SIMD architectures. The key to this system is an algorithm \n",
      "that allows the formation of arbitrary connections between the 'neurons '. A \n",
      "feature is the ability to add new connections quickly. It also has error recov- \n",
      "ery ability and is robust over a variety of network topologies. Si\n"
     ]
    }
   ],
   "source": [
    "print(papers[3][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NNqkh2nb8qpe"
   },
   "source": [
    "# Basic Text Pre-processing\n",
    "\n",
    "We perform some basic text wrangling or preprocessing before diving into topic\n",
    "modeling. We keep things simple here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "Jhsbee7g8lwa",
    "outputId": "9bfa633e-f36e-4030-abe2-c1fdecb16a30"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1740/1740 [00:30<00:00, 57.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1740\n",
      "CPU times: user 29.8 s, sys: 391 ms, total: 30.2 s\n",
      "Wall time: 30.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import nltk\n",
    "import tqdm\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "wtk = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "wnl = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def normalize_corpus(papers):\n",
    "    norm_papers = []\n",
    "    for paper in tqdm.tqdm(papers):\n",
    "        paper = paper.lower()\n",
    "        paper_tokens = [token.strip() for token in wtk.tokenize(paper)]\n",
    "        paper_tokens = [wnl.lemmatize(token) for token in paper_tokens if not token.isnumeric()]\n",
    "        paper_tokens = [token for token in paper_tokens if len(token) > 1]\n",
    "        paper_tokens = [token for token in paper_tokens if token not in stop_words]\n",
    "        paper_tokens = list(filter(None, paper_tokens))\n",
    "        if paper_tokens:\n",
    "            norm_papers.append(paper_tokens)\n",
    "            \n",
    "    return norm_papers\n",
    "    \n",
    "norm_papers = normalize_corpus(papers)\n",
    "print(len(norm_papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Cq4EhTwP-I_U",
    "outputId": "657ecdfe-4b2c-4572-a48e-eca9632b07dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['capacity', 'pattern', 'sequence', 'kanerva', 'sdm', 'compared', 'associative', 'memory', 'model', 'james', 'keeler', 'chemistry', 'department', 'stanford', 'university', 'stanford', 'ca', 'riacs', 'nasa', 'ames', 'moffett', 'field', 'ca', 'rnail', 'jdk', 'hydra', 'riacs', 'edu', 'abstract', 'information', 'capacity', 'kanerva', 'sparse', 'distributed', 'memory', 'sdm', 'hopfield', 'type', 'neural', 'network', 'investigated', 'approximation', 'used', 'shown', 'tal', 'information', 'stored', 'system', 'proportional', 'number']\n"
     ]
    }
   ],
   "source": [
    "print(norm_papers[0][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wFubckun_IYp"
   },
   "source": [
    "# Build a Bi-gram Phrase Model\n",
    "\n",
    "Before feature engineering and vectorization, we want to extract some useful bi-gram\n",
    "based phrases from our research papers and remove some unnecessary terms. We\n",
    "leverage the very useful gensim.models.Phrases class for this. This capability helps us\n",
    "automatically detect common phrases from a stream of sentences, which are typically\n",
    "multi-word expressions/word n-grams. \n",
    "\n",
    "This implementation draws inspiration\n",
    "from the famous paper by Mikolov, et al., “Distributed Representations of Words and\n",
    "Phrases and their Compositionality,” which you can check out at https://arxiv.org/\n",
    "abs/1310.4546. We start by extracting and generating words and bi-grams as phrases for\n",
    "each tokenized research paper. \n",
    "\n",
    "We leverage the `min_count` parameter, which tells us that our model ignores all words and bi-grams with total\n",
    "collected count lower than 20 across the corpus (of the input paper as a list of tokenized\n",
    "sentences). We also use a `threshold` of 20, which tells us that the model accepts specific\n",
    "phrases based on this threshold value so that a phrase of words a followed by b is\n",
    "accepted if the score of the phrase is greater than the threshold of 20. This threshold is\n",
    "dependent on the scoring parameter, which helps us understand how these phrases are\n",
    "scored to understand their influence.\n",
    "Typically the default scorer is used and it’s pretty straightforward to understand.\n",
    "You can check out further details in the documentation at https://radimrehurek.com/\n",
    "gensim/models/phrases.html#gensim.models.phrases.original_scorer and in the\n",
    "previously mentioned research paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "6IX3-ZbQ-fXp",
    "outputId": "9435dcb7-2a23-496e-abcc-d77d57568dec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['capacity', 'pattern', 'sequence', 'kanerva', 'sdm', 'compared', 'associative_memory', 'model', 'james', 'keeler', 'chemistry', 'department', 'stanford_university', 'stanford_ca', 'riacs', 'nasa_ames', 'moffett', 'field', 'ca', 'rnail', 'jdk', 'hydra', 'riacs', 'edu_abstract', 'information', 'capacity', 'kanerva_sparse', 'distributed', 'memory', 'sdm', 'hopfield', 'type', 'neural_network', 'investigated', 'approximation', 'used', 'shown', 'tal', 'information', 'stored', 'system', 'proportional', 'number', 'connection', 'net_work', 'proportionality', 'constant', 'sdm', 'hopfield', 'type']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "bigram = gensim.models.Phrases(norm_papers, min_count=20, threshold=20, delimiter=b'_') # higher threshold fewer phrases.\n",
    "bigram_model = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "print(bigram_model[norm_papers[0]][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "KaGCzYSU-jx1",
    "outputId": "8e8c8f15-ebe0-4e19-fe5b-c5c903e1df28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample word to number mappings: [(0, '000b'), (1, '100'), (2, '10g2m'), (3, '124a'), (4, '152m'), (5, '15m'), (6, '15n'), (7, '1n'), (8, '22d'), (9, '2b'), (10, '2d'), (11, '2dt'), (12, '2e'), (13, '2jr'), (14, '2mrr')]\n",
      "Total Vocabulary Size: 78892\n"
     ]
    }
   ],
   "source": [
    "norm_corpus_bigrams = [bigram_model[doc] for doc in norm_papers]\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = gensim.corpora.Dictionary(norm_corpus_bigrams)\n",
    "print('Sample word to number mappings:', list(dictionary.items())[:15])\n",
    "print('Total Vocabulary Size:', len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x47ztNpD12bC"
   },
   "source": [
    "Looks like we have a lot of unique phrases in our corpus of research papers,\n",
    "based on the preceding output. Several of these terms are not very useful since they are\n",
    "specific to a paper or even a paragraph in a research paper. Hence, it is time to prune\n",
    "our vocabulary and start removing terms. Leveraging document frequency is a great way\n",
    "to achieve this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YTiZ2Bxe-tNK",
    "outputId": "7d7de609-1ca9-43f4-e450-d134f8d8a0e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocabulary Size: 7756\n"
     ]
    }
   ],
   "source": [
    "# Filter out words that occur less than 20 documents, or more than 60% of the documents.\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.6)\n",
    "print('Total Vocabulary Size:', len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PKMDWQ6W12bF"
   },
   "source": [
    "We removed all terms that occur fewer than 20 times across all documents and all\n",
    "terms that occur in more than 60% of all the documents. We are interested in finding\n",
    "different themes and topics and not recurring themes. Hence, this suits our scenario\n",
    "perfectly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kj2lB4_b_eFO"
   },
   "source": [
    "# Transforming corpus into bag of words vectors\n",
    "\n",
    "We can now perform feature engineering by leveraging a simple Bag of Words\n",
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "cp_fhm91-3R-",
    "outputId": "0610c09b-1f24-4856-9b15-7bd7e6856b5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(7, 1), (9, 1), (14, 1), (15, 1), (16, 26), (20, 1), (32, 1), (33, 1), (35, 6), (36, 2), (38, 1), (42, 1), (45, 1), (46, 1), (49, 2), (50, 2), (51, 1), (54, 7), (55, 5), (59, 1), (60, 1), (65, 1), (75, 1), (82, 1), (83, 1), (97, 1), (101, 1), (103, 28), (106, 1), (108, 5), (110, 7), (111, 8), (120, 1), (129, 1), (130, 7), (131, 4), (134, 1), (139, 13), (143, 1), (145, 1), (148, 2), (155, 2), (156, 1), (160, 1), (161, 4), (164, 1), (176, 1), (177, 6), (185, 3), (189, 3)]\n"
     ]
    }
   ],
   "source": [
    "# Transforming corpus into bag of words vectors\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in norm_corpus_bigrams]\n",
    "print(bow_corpus[1][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "_oOA652d-6sI",
    "outputId": "b1676a40-8792-4012-85e7-a08d7411188d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('able', 1), ('acad_sci', 1), ('acknowledgement', 1), ('activation', 1), ('activity', 26), ('addition', 1), ('allowed', 1), ('allows', 1), ('alone', 6), ('although', 2), ('american_institute', 1), ('another', 1), ('apart', 1), ('appears', 1), ('approximate', 2), ('approximately', 2), ('approximation', 1), ('associated', 7), ('association', 5), ('assumption', 1), ('assumption_made', 1), ('average', 1), ('behavior', 1), ('biol', 1), ('biological', 1), ('calculation', 1), ('carried', 1), ('cell', 28), ('cerebral', 1), ('change', 5), ('channel', 7), ('characteristic', 8), ('coded', 1), ('compare', 1), ('compared', 7), ('comparison', 4), ('computing', 1), ('connection', 13), ('constant', 1), ('construct', 1), ('context', 2), ('convergence', 2), ('converges', 1), ('corresponding', 1), ('could', 4), ('cross', 1), ('demonstrate', 1), ('demonstrated', 6), ('dependent', 3), ('detail', 3)]\n"
     ]
    }
   ],
   "source": [
    "print([(dictionary[idx] , freq) for idx, freq in bow_corpus[1][:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aAjuxxdH--fn",
    "outputId": "a8a87e1a-3c8e-4ce0-fd69-2578f3362d74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of papers: 1740\n"
     ]
    }
   ],
   "source": [
    "print('Total number of papers:', len(bow_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zUb8ZKJXJI-4"
   },
   "source": [
    "# Topic Models with Latent Dirichlet Allocation (LDA)\n",
    "\n",
    "The Latent Dirichlet Allocation (LDA) technique is a generative probabilistic model in\n",
    "which each document is assumed to have a combination of topics similar to a probabilistic\n",
    "Latent Semantic Indexing model. In this case, the latent topics contain a Dirichlet\n",
    "prior over them. The math behind in this technique is pretty involved, so we will try to\n",
    "summarize it since going it specific details is out of the current scope.\n",
    "\n",
    "![](https://i.imgur.com/l23JAvE.png)\n",
    "\n",
    "Simplyfying the LDA model process:\n",
    "\n",
    "![](https://i.imgur.com/0BXCaUi.png)\n",
    "\n",
    "![](https://i.imgur.com/ioiUAxX.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "083_UQPlJZy_",
    "outputId": "0bc6fa0e-84ca-4df3-c332-0039025c115a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 47s, sys: 1.99 s, total: 1min 49s\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TOTAL_TOPICS = 10\n",
    "lda_model = gensim.models.LdaModel(corpus=bow_corpus, id2word=dictionary, chunksize=1740, \n",
    "                                   alpha='auto', eta='auto', random_state=42,\n",
    "                                   iterations=500, num_topics=TOTAL_TOPICS, \n",
    "                                   passes=20, eval_every=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "colab_type": "code",
    "id": "IF9KX9UARO1r",
    "outputId": "961c1563-8c42-4a25-ede0-a09a8af5a76a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "0.009*\"vector\" + 0.006*\"unit\" + 0.006*\"pattern\" + 0.006*\"neuron\" + 0.006*\"equation\" + 0.005*\"matrix\" + 0.005*\"training\" + 0.005*\"noise\" + 0.005*\"dynamic\" + 0.004*\"linear\" + 0.004*\"hidden_unit\" + 0.004*\"solution\" + 0.003*\"layer\" + 0.003*\"eq\" + 0.003*\"rule\" + 0.003*\"distribution\" + 0.003*\"rate\" + 0.003*\"capacity\" + 0.003*\"state\" + 0.003*\"attractor\"\n",
      "\n",
      "Topic #2:\n",
      "0.018*\"state\" + 0.012*\"unit\" + 0.009*\"task\" + 0.008*\"action\" + 0.006*\"step\" + 0.006*\"representation\" + 0.005*\"training\" + 0.005*\"memory\" + 0.005*\"pattern\" + 0.004*\"sequence\" + 0.004*\"policy\" + 0.004*\"activation\" + 0.004*\"recurrent\" + 0.004*\"structure\" + 0.003*\"net\" + 0.003*\"hidden_unit\" + 0.003*\"reinforcement_learning\" + 0.003*\"architecture\" + 0.003*\"learn\" + 0.003*\"environment\"\n",
      "\n",
      "Topic #3:\n",
      "0.018*\"neuron\" + 0.017*\"cell\" + 0.009*\"response\" + 0.009*\"stimulus\" + 0.007*\"activity\" + 0.007*\"pattern\" + 0.006*\"spike\" + 0.006*\"signal\" + 0.005*\"synaptic\" + 0.004*\"cortical\" + 0.004*\"frequency\" + 0.004*\"neural\" + 0.004*\"effect\" + 0.004*\"firing\" + 0.004*\"unit\" + 0.004*\"connection\" + 0.004*\"layer\" + 0.003*\"et_al\" + 0.003*\"cortex\" + 0.003*\"change\"\n",
      "\n",
      "Topic #4:\n",
      "0.006*\"class\" + 0.006*\"distribution\" + 0.006*\"probability\" + 0.005*\"variable\" + 0.005*\"estimate\" + 0.005*\"sample\" + 0.005*\"bound\" + 0.005*\"let\" + 0.004*\"approximation\" + 0.004*\"kernel\" + 0.004*\"linear\" + 0.004*\"theorem\" + 0.003*\"training\" + 0.003*\"size\" + 0.003*\"xi\" + 0.003*\"optimal\" + 0.003*\"vector\" + 0.003*\"theory\" + 0.003*\"regression\" + 0.003*\"note\"\n",
      "\n",
      "Topic #5:\n",
      "0.014*\"circuit\" + 0.012*\"chip\" + 0.010*\"neuron\" + 0.008*\"analog\" + 0.008*\"current\" + 0.007*\"voltage\" + 0.007*\"image\" + 0.006*\"signal\" + 0.005*\"bit\" + 0.004*\"processor\" + 0.004*\"implementation\" + 0.004*\"neural\" + 0.004*\"computation\" + 0.004*\"element\" + 0.004*\"synapse\" + 0.004*\"design\" + 0.003*\"device\" + 0.003*\"digital\" + 0.003*\"threshold\" + 0.003*\"transistor\"\n",
      "\n",
      "Topic #6:\n",
      "0.014*\"training\" + 0.012*\"classifier\" + 0.011*\"class\" + 0.010*\"classification\" + 0.010*\"node\" + 0.008*\"pattern\" + 0.008*\"rule\" + 0.007*\"feature\" + 0.006*\"vector\" + 0.006*\"unit\" + 0.005*\"tree\" + 0.005*\"training_set\" + 0.004*\"test\" + 0.004*\"trained\" + 0.004*\"probability\" + 0.003*\"table\" + 0.003*\"layer\" + 0.003*\"task\" + 0.003*\"experiment\" + 0.003*\"size\"\n",
      "\n",
      "Topic #7:\n",
      "0.007*\"gaussian\" + 0.007*\"distribution\" + 0.007*\"prior\" + 0.006*\"training\" + 0.006*\"mixture\" + 0.005*\"noise\" + 0.005*\"prediction\" + 0.005*\"bayesian\" + 0.005*\"estimate\" + 0.004*\"source\" + 0.004*\"approximation\" + 0.004*\"variance\" + 0.004*\"cluster\" + 0.004*\"component\" + 0.004*\"posterior\" + 0.004*\"density\" + 0.004*\"step\" + 0.004*\"expert\" + 0.004*\"sample\" + 0.003*\"variable\"\n",
      "\n",
      "Topic #8:\n",
      "0.022*\"image\" + 0.012*\"object\" + 0.009*\"visual\" + 0.008*\"motion\" + 0.008*\"unit\" + 0.008*\"feature\" + 0.006*\"position\" + 0.006*\"map\" + 0.006*\"direction\" + 0.005*\"representation\" + 0.005*\"location\" + 0.004*\"view\" + 0.004*\"field\" + 0.004*\"target\" + 0.004*\"region\" + 0.004*\"layer\" + 0.004*\"local\" + 0.004*\"movement\" + 0.003*\"velocity\" + 0.003*\"task\"\n",
      "\n",
      "Topic #9:\n",
      "0.017*\"state\" + 0.013*\"control\" + 0.007*\"equation\" + 0.006*\"convergence\" + 0.006*\"optimal\" + 0.006*\"controller\" + 0.006*\"solution\" + 0.005*\"gradient\" + 0.005*\"vector\" + 0.005*\"dynamic\" + 0.005*\"matrix\" + 0.005*\"constraint\" + 0.005*\"trajectory\" + 0.005*\"rate\" + 0.004*\"step\" + 0.004*\"linear\" + 0.004*\"optimization\" + 0.004*\"nonlinear\" + 0.003*\"energy\" + 0.003*\"line\"\n",
      "\n",
      "Topic #10:\n",
      "0.012*\"word\" + 0.011*\"recognition\" + 0.011*\"training\" + 0.008*\"speech\" + 0.007*\"sequence\" + 0.006*\"state\" + 0.006*\"character\" + 0.006*\"feature\" + 0.005*\"hmm\" + 0.005*\"trained\" + 0.005*\"vector\" + 0.005*\"layer\" + 0.005*\"signal\" + 0.005*\"context\" + 0.004*\"frame\" + 0.004*\"unit\" + 0.004*\"net\" + 0.004*\"architecture\" + 0.004*\"speaker\" + 0.004*\"class\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic_id, topic in lda_model.print_topics(num_topics=10, num_words=20):\n",
    "    print('Topic #'+str(topic_id+1)+':')\n",
    "    print(topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4jExj9SYRRyE",
    "outputId": "2dccd682-bbbb-4788-9974-1401160e64e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Coherence Score: -1.0085059947648578\n"
     ]
    }
   ],
   "source": [
    "topics_coherences = lda_model.top_topics(bow_corpus, topn=20)\n",
    "avg_coherence_score = np.mean([item[1] for item in topics_coherences])\n",
    "print('Avg. Coherence Score:', avg_coherence_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YtPTIGeQ12by"
   },
   "source": [
    "Topic coherence is a complex topic in its own and it can be used to measure the\n",
    "quality of topic models to some extent. Typically, a set of statements is said to be\n",
    "coherent if they support each other. Topic models are unsupervised learning based\n",
    "models that are trained on unstructured text data, making it difficult to measure the\n",
    "quality of outputs. \n",
    "\n",
    "Refer to Text Analytics with Python 2nd Edition for more detail on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 574
    },
    "colab_type": "code",
    "id": "azEdB08qRX4z",
    "outputId": "ac576b55-6062-46b8-d0e6-c666d1e892e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Topics with Weights\n",
      "==================================================\n",
      "Topic #1:\n",
      "[('training', 0.014), ('classifier', 0.012), ('class', 0.011), ('classification', 0.01), ('node', 0.01), ('pattern', 0.008), ('rule', 0.008), ('feature', 0.007), ('vector', 0.006), ('unit', 0.006), ('tree', 0.005), ('training_set', 0.005), ('test', 0.004), ('trained', 0.004), ('probability', 0.004), ('table', 0.003), ('layer', 0.003), ('task', 0.003), ('experiment', 0.003), ('size', 0.003)]\n",
      "\n",
      "Topic #2:\n",
      "[('neuron', 0.018), ('cell', 0.017), ('response', 0.009), ('stimulus', 0.009), ('activity', 0.007), ('pattern', 0.007), ('spike', 0.006), ('signal', 0.006), ('synaptic', 0.005), ('cortical', 0.004), ('frequency', 0.004), ('neural', 0.004), ('effect', 0.004), ('firing', 0.004), ('unit', 0.004), ('connection', 0.004), ('layer', 0.004), ('et_al', 0.003), ('cortex', 0.003), ('change', 0.003)]\n",
      "\n",
      "Topic #3:\n",
      "[('class', 0.006), ('distribution', 0.006), ('probability', 0.006), ('variable', 0.005), ('estimate', 0.005), ('sample', 0.005), ('bound', 0.005), ('let', 0.005), ('approximation', 0.004), ('kernel', 0.004), ('linear', 0.004), ('theorem', 0.004), ('training', 0.003), ('size', 0.003), ('xi', 0.003), ('optimal', 0.003), ('vector', 0.003), ('theory', 0.003), ('regression', 0.003), ('note', 0.003)]\n",
      "\n",
      "Topic #4:\n",
      "[('state', 0.017), ('control', 0.013), ('equation', 0.007), ('convergence', 0.006), ('optimal', 0.006), ('controller', 0.006), ('solution', 0.006), ('gradient', 0.005), ('vector', 0.005), ('dynamic', 0.005), ('matrix', 0.005), ('constraint', 0.005), ('trajectory', 0.005), ('rate', 0.005), ('step', 0.004), ('linear', 0.004), ('optimization', 0.004), ('nonlinear', 0.004), ('energy', 0.003), ('line', 0.003)]\n",
      "\n",
      "Topic #5:\n",
      "[('image', 0.022), ('object', 0.012), ('visual', 0.009), ('motion', 0.008), ('unit', 0.008), ('feature', 0.008), ('position', 0.006), ('map', 0.006), ('direction', 0.006), ('representation', 0.005), ('location', 0.005), ('view', 0.004), ('field', 0.004), ('target', 0.004), ('region', 0.004), ('layer', 0.004), ('local', 0.004), ('movement', 0.004), ('velocity', 0.003), ('task', 0.003)]\n",
      "\n",
      "Topic #6:\n",
      "[('word', 0.012), ('recognition', 0.011), ('training', 0.011), ('speech', 0.008), ('sequence', 0.007), ('state', 0.006), ('character', 0.006), ('feature', 0.006), ('hmm', 0.005), ('trained', 0.005), ('vector', 0.005), ('layer', 0.005), ('signal', 0.005), ('context', 0.005), ('frame', 0.004), ('unit', 0.004), ('net', 0.004), ('architecture', 0.004), ('speaker', 0.004), ('class', 0.004)]\n",
      "\n",
      "Topic #7:\n",
      "[('gaussian', 0.007), ('distribution', 0.007), ('prior', 0.007), ('training', 0.006), ('mixture', 0.006), ('noise', 0.005), ('prediction', 0.005), ('bayesian', 0.005), ('estimate', 0.005), ('source', 0.004), ('approximation', 0.004), ('variance', 0.004), ('cluster', 0.004), ('component', 0.004), ('posterior', 0.004), ('density', 0.004), ('step', 0.004), ('expert', 0.004), ('sample', 0.004), ('variable', 0.003)]\n",
      "\n",
      "Topic #8:\n",
      "[('vector', 0.009), ('unit', 0.006), ('pattern', 0.006), ('neuron', 0.006), ('equation', 0.006), ('matrix', 0.005), ('training', 0.005), ('noise', 0.005), ('dynamic', 0.005), ('linear', 0.004), ('hidden_unit', 0.004), ('solution', 0.004), ('layer', 0.003), ('eq', 0.003), ('rule', 0.003), ('distribution', 0.003), ('rate', 0.003), ('capacity', 0.003), ('state', 0.003), ('attractor', 0.003)]\n",
      "\n",
      "Topic #9:\n",
      "[('circuit', 0.014), ('chip', 0.012), ('neuron', 0.01), ('analog', 0.008), ('current', 0.008), ('voltage', 0.007), ('image', 0.007), ('signal', 0.006), ('bit', 0.005), ('processor', 0.004), ('implementation', 0.004), ('neural', 0.004), ('computation', 0.004), ('element', 0.004), ('synapse', 0.004), ('design', 0.004), ('device', 0.003), ('digital', 0.003), ('threshold', 0.003), ('transistor', 0.003)]\n",
      "\n",
      "Topic #10:\n",
      "[('state', 0.018), ('unit', 0.012), ('task', 0.009), ('action', 0.008), ('step', 0.006), ('representation', 0.006), ('training', 0.005), ('memory', 0.005), ('pattern', 0.005), ('sequence', 0.004), ('policy', 0.004), ('activation', 0.004), ('recurrent', 0.004), ('structure', 0.004), ('net', 0.003), ('hidden_unit', 0.003), ('reinforcement_learning', 0.003), ('architecture', 0.003), ('learn', 0.003), ('environment', 0.003)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topics_with_wts = [item[0] for item in topics_coherences]\n",
    "print('LDA Topics with Weights')\n",
    "print('='*50)\n",
    "for idx, topic in enumerate(topics_with_wts):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([(term, round(wt, 3)) for wt, term in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 574
    },
    "colab_type": "code",
    "id": "EAkgJa3XRZ3m",
    "outputId": "15e74b7d-4904-4197-f86a-16b97f163269"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Topics without Weights\n",
      "==================================================\n",
      "Topic #1:\n",
      "['training', 'classifier', 'class', 'classification', 'node', 'pattern', 'rule', 'feature', 'vector', 'unit', 'tree', 'training_set', 'test', 'trained', 'probability', 'table', 'layer', 'task', 'experiment', 'size']\n",
      "\n",
      "Topic #2:\n",
      "['neuron', 'cell', 'response', 'stimulus', 'activity', 'pattern', 'spike', 'signal', 'synaptic', 'cortical', 'frequency', 'neural', 'effect', 'firing', 'unit', 'connection', 'layer', 'et_al', 'cortex', 'change']\n",
      "\n",
      "Topic #3:\n",
      "['class', 'distribution', 'probability', 'variable', 'estimate', 'sample', 'bound', 'let', 'approximation', 'kernel', 'linear', 'theorem', 'training', 'size', 'xi', 'optimal', 'vector', 'theory', 'regression', 'note']\n",
      "\n",
      "Topic #4:\n",
      "['state', 'control', 'equation', 'convergence', 'optimal', 'controller', 'solution', 'gradient', 'vector', 'dynamic', 'matrix', 'constraint', 'trajectory', 'rate', 'step', 'linear', 'optimization', 'nonlinear', 'energy', 'line']\n",
      "\n",
      "Topic #5:\n",
      "['image', 'object', 'visual', 'motion', 'unit', 'feature', 'position', 'map', 'direction', 'representation', 'location', 'view', 'field', 'target', 'region', 'layer', 'local', 'movement', 'velocity', 'task']\n",
      "\n",
      "Topic #6:\n",
      "['word', 'recognition', 'training', 'speech', 'sequence', 'state', 'character', 'feature', 'hmm', 'trained', 'vector', 'layer', 'signal', 'context', 'frame', 'unit', 'net', 'architecture', 'speaker', 'class']\n",
      "\n",
      "Topic #7:\n",
      "['gaussian', 'distribution', 'prior', 'training', 'mixture', 'noise', 'prediction', 'bayesian', 'estimate', 'source', 'approximation', 'variance', 'cluster', 'component', 'posterior', 'density', 'step', 'expert', 'sample', 'variable']\n",
      "\n",
      "Topic #8:\n",
      "['vector', 'unit', 'pattern', 'neuron', 'equation', 'matrix', 'training', 'noise', 'dynamic', 'linear', 'hidden_unit', 'solution', 'layer', 'eq', 'rule', 'distribution', 'rate', 'capacity', 'state', 'attractor']\n",
      "\n",
      "Topic #9:\n",
      "['circuit', 'chip', 'neuron', 'analog', 'current', 'voltage', 'image', 'signal', 'bit', 'processor', 'implementation', 'neural', 'computation', 'element', 'synapse', 'design', 'device', 'digital', 'threshold', 'transistor']\n",
      "\n",
      "Topic #10:\n",
      "['state', 'unit', 'task', 'action', 'step', 'representation', 'training', 'memory', 'pattern', 'sequence', 'policy', 'activation', 'recurrent', 'structure', 'net', 'hidden_unit', 'reinforcement_learning', 'architecture', 'learn', 'environment']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('LDA Topics without Weights')\n",
    "print('='*50)\n",
    "for idx, topic in enumerate(topics_with_wts):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([term for wt, term in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "abiy8_Cg12b5"
   },
   "source": [
    "## Evaluating topic model quality\n",
    "\n",
    "We can use perplexity and coherence scores as measures to evaluate the topic\n",
    "model. Typically, lower the perplexity, the better the model. Similarly, the lower the\n",
    "UMass score and the higher the Cv score in coherence, the better the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "WkOZQdZERbzG",
    "outputId": "14f94cd4-6c45-4c8f-9936-c82a6bf93467"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Coherence Score (Cv): 0.46465493030372984\n",
      "Avg. Coherence Score (UMass): -1.0085059947648576\n",
      "Model Perplexity: -7.7898927129844004\n"
     ]
    }
   ],
   "source": [
    "cv_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus, \n",
    "                                                      texts=norm_corpus_bigrams,\n",
    "                                                      dictionary=dictionary, \n",
    "                                                      coherence='c_v')\n",
    "avg_coherence_cv = cv_coherence_model_lda.get_coherence()\n",
    "\n",
    "umass_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus, \n",
    "                                                         texts=norm_corpus_bigrams,\n",
    "                                                         dictionary=dictionary, \n",
    "                                                         coherence='u_mass')\n",
    "avg_coherence_umass = umass_coherence_model_lda.get_coherence()\n",
    "\n",
    "perplexity = lda_model.log_perplexity(bow_corpus)\n",
    "\n",
    "print('Avg. Coherence Score (Cv):', avg_coherence_cv)\n",
    "print('Avg. Coherence Score (UMass):', avg_coherence_umass)\n",
    "print('Model Perplexity:', perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DmuExSjK12b6"
   },
   "source": [
    "# LDA Models with MALLET\n",
    "\n",
    "The MALLET framework is a Java-based package for statistical natural language\n",
    "processing, document classification, clustering, topic modeling, information extraction,\n",
    "and other machine learning applications to text. MALLET stands for MAchine Learning\n",
    "for LanguagE Toolkit. It was developed by Andrew McCallum along with several people\n",
    "at the University of Massachusetts Amherst. The MALLET topic modeling toolkit\n",
    "contains efficient, sampling-based implementations of Latent Dirichlet Allocation,\n",
    "Pachinko Allocation, and Hierarchical LDA. To use MALLET’s capabilities, we need to\n",
    "download the framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "NSRYjYP7VXPz",
    "outputId": "913a2c71-2eee-4c61-ea62-3bbf5475b3c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-27 16:31:43--  http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
      "Resolving mallet.cs.umass.edu (mallet.cs.umass.edu)... 128.119.246.70\n",
      "Connecting to mallet.cs.umass.edu (mallet.cs.umass.edu)|128.119.246.70|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16184794 (15M) [application/zip]\n",
      "Saving to: ‘mallet-2.0.8.zip’\n",
      "\n",
      "mallet-2.0.8.zip    100%[===================>]  15.43M  18.2MB/s    in 0.8s    \n",
      "\n",
      "2020-05-27 16:31:44 (18.2 MB/s) - ‘mallet-2.0.8.zip’ saved [16184794/16184794]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "!unzip -q mallet-2.0.8.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "s0J3x_IcVu8z",
    "outputId": "1fa68c7e-f37e-4d66-84fb-ed6914da1393"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "MALLET_PATH = 'mallet-2.0.8/bin/mallet'\n",
    "lda_mallet = gensim.models.wrappers.LdaMallet(mallet_path=MALLET_PATH, corpus=bow_corpus, \n",
    "                                              num_topics=TOTAL_TOPICS, id2word=dictionary,\n",
    "                                              iterations=500, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "HQcf70_0WHDc",
    "outputId": "3fd66f35-5d15-47d9-c93e-eb3d7b35a87f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Coherence Score (Cv): 0.51312347075612\n",
      "Avg. Coherence Score (UMass): -1.0559523073857255\n",
      "Model Perplexity: -8.50105\n"
     ]
    }
   ],
   "source": [
    "cv_coherence_model_lda_mallet = gensim.models.CoherenceModel(model=lda_mallet, corpus=bow_corpus, \n",
    "                                                             texts=norm_corpus_bigrams,\n",
    "                                                             dictionary=dictionary, \n",
    "                                                             coherence='c_v')\n",
    "avg_coherence_cv = cv_coherence_model_lda_mallet.get_coherence()\n",
    "\n",
    "umass_coherence_model_lda_mallet = gensim.models.CoherenceModel(model=lda_mallet, corpus=bow_corpus, \n",
    "                                                                texts=norm_corpus_bigrams,\n",
    "                                                                dictionary=dictionary,  \n",
    "                                                                coherence='u_mass')\n",
    "avg_coherence_umass = umass_coherence_model_lda_mallet.get_coherence()\n",
    "\n",
    "# from STDOUT: <500> LL/token: -8.50105\n",
    "perplexity = -8.50105\n",
    "print('Avg. Coherence Score (Cv):', avg_coherence_cv)\n",
    "print('Avg. Coherence Score (UMass):', avg_coherence_umass)\n",
    "print('Model Perplexity:', perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wvn6Xx9N12cA"
   },
   "source": [
    "# LDA Tuning: Finding the optimal number of topics\n",
    "\n",
    "Finding the optimal number of topics in a topic model is tough, given that it is like a\n",
    "model hyperparameter that you always have to set before training the model. We can\n",
    "use an iterative approach and build several models with differing numbers of topics and\n",
    "select the one that has the highest coherence score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OYeyeNmRWy4m"
   },
   "outputs": [],
   "source": [
    "def topic_model_coherence_generator(corpus, texts, dictionary, \n",
    "                                    start_topic_count=2, end_topic_count=10, step=1,\n",
    "                                    cpus=1):\n",
    "    \n",
    "    models = []\n",
    "    coherence_scores = []\n",
    "    for topic_nums in tqdm.tqdm(range(start_topic_count, end_topic_count+1, step)):\n",
    "        mallet_lda_model = gensim.models.wrappers.LdaMallet(mallet_path=MALLET_PATH, corpus=corpus,\n",
    "                                                            num_topics=topic_nums, id2word=dictionary,\n",
    "                                                            iterations=500, workers=cpus)\n",
    "        cv_coherence_model_mallet_lda = gensim.models.CoherenceModel(model=mallet_lda_model, corpus=corpus, \n",
    "                                                                     texts=texts, dictionary=dictionary, \n",
    "                                                                     coherence='c_v')\n",
    "        coherence_score = cv_coherence_model_mallet_lda.get_coherence()\n",
    "        coherence_scores.append(coherence_score)\n",
    "        models.append(mallet_lda_model)\n",
    "    \n",
    "    return models, coherence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "8vgKu5RCXHrv",
    "outputId": "bbcf4798-8ff6-4750-f27a-467f59786259"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/29 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "100%|██████████| 29/29 [1:35:47<00:00, 198.18s/it]\n"
     ]
    }
   ],
   "source": [
    "lda_models, coherence_scores = topic_model_coherence_generator(corpus=bow_corpus, texts=norm_corpus_bigrams,\n",
    "                                                               dictionary=dictionary, start_topic_count=2,\n",
    "                                                               end_topic_count=30, step=1, cpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "EeQIjHsOXPvY",
    "outputId": "b865b9f5-7be1-4e44-d14b-34809e9f2645"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Topics</th>\n",
       "      <th>Coherence Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>0.5492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>0.5425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27</td>\n",
       "      <td>0.5404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>26</td>\n",
       "      <td>0.5367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>0.5366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>0.5365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21</td>\n",
       "      <td>0.5353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>0.5342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>29</td>\n",
       "      <td>0.5340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>0.5327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number of Topics  Coherence Score\n",
       "13                15           0.5492\n",
       "18                20           0.5425\n",
       "25                27           0.5404\n",
       "24                26           0.5367\n",
       "20                22           0.5366\n",
       "21                23           0.5365\n",
       "19                21           0.5353\n",
       "15                17           0.5342\n",
       "27                29           0.5340\n",
       "17                19           0.5327"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_df = pd.DataFrame({'Number of Topics': range(2, 31, 1),\n",
    "                             'Coherence Score': np.round(coherence_scores, 4)})\n",
    "coherence_df.sort_values(by=['Coherence Score'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "colab_type": "code",
    "id": "UBSRO_VqYjif",
    "outputId": "56d48181-4df7-4ea1-cbcb-682ab9460fd6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "\n",
    "x_ax = range(2, 31, 1)\n",
    "y_ax = coherence_scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x_ax, y_ax, c='r')\n",
    "plt.axhline(y=0.535, c='k', linestyle='--', linewidth=2)\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "xl = plt.xlabel('Number of Topics')\n",
    "yl = plt.ylabel('Coherence Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N7PlAhgx12cI"
   },
   "source": [
    "We choose the optimal number of topics as 15, based on our intuition. We can retrieve the best model now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YtPwVFdrYlxO",
    "outputId": "9a9938ef-b031-454a-8033-da7ce972bd30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_idx = coherence_df[coherence_df['Number of Topics'] == 15].index[0]\n",
    "best_lda_model = lda_models[best_model_idx]\n",
    "best_lda_model.num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 793
    },
    "colab_type": "code",
    "id": "sQj6L5w4lWXa",
    "outputId": "7fddcc22-ca39-41bd-f881-dcecc52b4548"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "['signal', 'noise', 'source', 'frequency', 'filter', 'channel', 'component', 'adaptation', 'detection', 'sound', 'auditory', 'temporal', 'correlation', 'ica', 'response', 'rate', 'phase', 'amplitude', 'coding', 'change']\n",
      "\n",
      "Topic #2:\n",
      "['map', 'activity', 'target', 'representation', 'human', 'subject', 'eye', 'motor', 'structure', 'pattern', 'movement', 'stimulus', 'position', 'module', 'visual', 'location', 'development', 'brain', 'response', 'cue']\n",
      "\n",
      "Topic #3:\n",
      "['image', 'motion', 'visual', 'direction', 'region', 'field', 'orientation', 'pixel', 'receptive_field', 'location', 'local', 'edge', 'spatial', 'center', 'position', 'velocity', 'object', 'surface', 'response', 'contour']\n",
      "\n",
      "Topic #4:\n",
      "['vector', 'matrix', 'solution', 'equation', 'convergence', 'linear', 'gradient', 'constraint', 'rate', 'nonlinear', 'optimal', 'optimization', 'iteration', 'eq', 'update', 'constant', 'minimum', 'energy', 'line', 'gradient_descent']\n",
      "\n",
      "Topic #5:\n",
      "['neuron', 'cell', 'response', 'stimulus', 'synaptic', 'spike', 'activity', 'firing', 'cortical', 'pattern', 'connection', 'synapsis', 'et_al', 'neural', 'effect', 'cortex', 'current', 'threshold', 'neuronal', 'layer']\n",
      "\n",
      "Topic #6:\n",
      "['dynamic', 'state', 'memory', 'pattern', 'neuron', 'equation', 'phase', 'recurrent', 'attractor', 'capacity', 'fixed_point', 'correlation', 'hopfield', 'fig', 'behavior', 'stable', 'theory', 'delay', 'noise', 'connection']\n",
      "\n",
      "Topic #7:\n",
      "['node', 'class', 'classification', 'classifier', 'training', 'tree', 'pattern', 'test', 'sample', 'feature', 'search', 'table', 'technique', 'experiment', 'rbf', 'expert', 'training_set', 'accuracy', 'machine', 'application']\n",
      "\n",
      "Topic #8:\n",
      "['distribution', 'probability', 'gaussian', 'variable', 'prior', 'density', 'estimate', 'mixture', 'approximation', 'bayesian', 'sample', 'estimation', 'component', 'likelihood', 'log', 'em', 'step', 'variance', 'entropy', 'posterior']\n",
      "\n",
      "Topic #9:\n",
      "['unit', 'layer', 'net', 'hidden_unit', 'training', 'rule', 'pattern', 'architecture', 'task', 'activation', 'trained', 'back_propagation', 'hidden_layer', 'learn', 'connection', 'hidden', 'generalization', 'backpropagation', 'connectionist', 'step']\n",
      "\n",
      "Topic #10:\n",
      "['circuit', 'chip', 'current', 'bit', 'analog', 'neuron', 'voltage', 'implementation', 'code', 'processor', 'design', 'operation', 'element', 'parallel', 'neural', 'computation', 'device', 'digital', 'architecture', 'implemented']\n",
      "\n",
      "Topic #11:\n",
      "['word', 'sequence', 'recognition', 'training', 'state', 'context', 'speech', 'character', 'hmm', 'letter', 'language', 'frame', 'string', 'symbol', 'speaker', 'recurrent', 'trained', 'speech_recognition', 'phoneme', 'experiment']\n",
      "\n",
      "Topic #12:\n",
      "['state', 'control', 'action', 'step', 'policy', 'task', 'trajectory', 'environment', 'controller', 'reinforcement_learning', 'goal', 'robot', 'optimal', 'current', 'reward', 'move', 'learned', 'trial', 'path', 'td']\n",
      "\n",
      "Topic #13:\n",
      "['feature', 'image', 'vector', 'representation', 'object', 'cluster', 'distance', 'transformation', 'face', 'structure', 'view', 'clustering', 'recognition', 'part', 'dimension', 'mapping', 'similarity', 'dimensional', 'digit', 'pca']\n",
      "\n",
      "Topic #14:\n",
      "['bound', 'theorem', 'class', 'size', 'theory', 'probability', 'approximation', 'threshold', 'complexity', 'defined', 'proof', 'linear', 'loss', 'polynomial', 'hypothesis', 'kernel', 'assume', 'definition', 'concept', 'xi']\n",
      "\n",
      "Topic #15:\n",
      "['training', 'prediction', 'noise', 'average', 'training_set', 'test', 'estimate', 'regression', 'optimal', 'variance', 'ensemble', 'linear', 'curve', 'effect', 'bias', 'expected', 'generalization_error', 'generalization', 'selection', 'size']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topics = [[(term, round(wt, 3)) \n",
    "               for term, wt in best_lda_model.show_topic(n, topn=20)] \n",
    "                   for n in range(0, best_lda_model.num_topics)]\n",
    "\n",
    "for idx, topic in enumerate(topics):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([term for term, wt in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mxtpl5Co12cL"
   },
   "source": [
    "# Viewing LDA Model topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 659
    },
    "colab_type": "code",
    "id": "V-SpgKYRpHsA",
    "outputId": "c38a1b80-c25b-40c0-9729-9c0e2d8f2a3e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "      <th>Topic 5</th>\n",
       "      <th>Topic 6</th>\n",
       "      <th>Topic 7</th>\n",
       "      <th>Topic 8</th>\n",
       "      <th>Topic 9</th>\n",
       "      <th>Topic 10</th>\n",
       "      <th>Topic 11</th>\n",
       "      <th>Topic 12</th>\n",
       "      <th>Topic 13</th>\n",
       "      <th>Topic 14</th>\n",
       "      <th>Topic 15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Term1</th>\n",
       "      <td>signal</td>\n",
       "      <td>map</td>\n",
       "      <td>image</td>\n",
       "      <td>vector</td>\n",
       "      <td>neuron</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>node</td>\n",
       "      <td>distribution</td>\n",
       "      <td>unit</td>\n",
       "      <td>circuit</td>\n",
       "      <td>word</td>\n",
       "      <td>state</td>\n",
       "      <td>feature</td>\n",
       "      <td>bound</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term2</th>\n",
       "      <td>noise</td>\n",
       "      <td>activity</td>\n",
       "      <td>motion</td>\n",
       "      <td>matrix</td>\n",
       "      <td>cell</td>\n",
       "      <td>state</td>\n",
       "      <td>class</td>\n",
       "      <td>probability</td>\n",
       "      <td>layer</td>\n",
       "      <td>chip</td>\n",
       "      <td>sequence</td>\n",
       "      <td>control</td>\n",
       "      <td>image</td>\n",
       "      <td>theorem</td>\n",
       "      <td>prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term3</th>\n",
       "      <td>source</td>\n",
       "      <td>target</td>\n",
       "      <td>visual</td>\n",
       "      <td>solution</td>\n",
       "      <td>response</td>\n",
       "      <td>memory</td>\n",
       "      <td>classification</td>\n",
       "      <td>gaussian</td>\n",
       "      <td>net</td>\n",
       "      <td>current</td>\n",
       "      <td>recognition</td>\n",
       "      <td>action</td>\n",
       "      <td>vector</td>\n",
       "      <td>class</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term4</th>\n",
       "      <td>frequency</td>\n",
       "      <td>representation</td>\n",
       "      <td>direction</td>\n",
       "      <td>equation</td>\n",
       "      <td>stimulus</td>\n",
       "      <td>pattern</td>\n",
       "      <td>classifier</td>\n",
       "      <td>variable</td>\n",
       "      <td>hidden_unit</td>\n",
       "      <td>bit</td>\n",
       "      <td>training</td>\n",
       "      <td>step</td>\n",
       "      <td>representation</td>\n",
       "      <td>size</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term5</th>\n",
       "      <td>filter</td>\n",
       "      <td>human</td>\n",
       "      <td>region</td>\n",
       "      <td>convergence</td>\n",
       "      <td>synaptic</td>\n",
       "      <td>neuron</td>\n",
       "      <td>training</td>\n",
       "      <td>prior</td>\n",
       "      <td>training</td>\n",
       "      <td>analog</td>\n",
       "      <td>state</td>\n",
       "      <td>policy</td>\n",
       "      <td>object</td>\n",
       "      <td>theory</td>\n",
       "      <td>training_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term6</th>\n",
       "      <td>channel</td>\n",
       "      <td>subject</td>\n",
       "      <td>field</td>\n",
       "      <td>linear</td>\n",
       "      <td>spike</td>\n",
       "      <td>equation</td>\n",
       "      <td>tree</td>\n",
       "      <td>density</td>\n",
       "      <td>rule</td>\n",
       "      <td>neuron</td>\n",
       "      <td>context</td>\n",
       "      <td>task</td>\n",
       "      <td>cluster</td>\n",
       "      <td>probability</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term7</th>\n",
       "      <td>component</td>\n",
       "      <td>eye</td>\n",
       "      <td>orientation</td>\n",
       "      <td>gradient</td>\n",
       "      <td>activity</td>\n",
       "      <td>phase</td>\n",
       "      <td>pattern</td>\n",
       "      <td>estimate</td>\n",
       "      <td>pattern</td>\n",
       "      <td>voltage</td>\n",
       "      <td>speech</td>\n",
       "      <td>trajectory</td>\n",
       "      <td>distance</td>\n",
       "      <td>approximation</td>\n",
       "      <td>estimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term8</th>\n",
       "      <td>adaptation</td>\n",
       "      <td>motor</td>\n",
       "      <td>pixel</td>\n",
       "      <td>constraint</td>\n",
       "      <td>firing</td>\n",
       "      <td>recurrent</td>\n",
       "      <td>test</td>\n",
       "      <td>mixture</td>\n",
       "      <td>architecture</td>\n",
       "      <td>implementation</td>\n",
       "      <td>character</td>\n",
       "      <td>environment</td>\n",
       "      <td>transformation</td>\n",
       "      <td>threshold</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term9</th>\n",
       "      <td>detection</td>\n",
       "      <td>structure</td>\n",
       "      <td>receptive_field</td>\n",
       "      <td>rate</td>\n",
       "      <td>cortical</td>\n",
       "      <td>attractor</td>\n",
       "      <td>sample</td>\n",
       "      <td>approximation</td>\n",
       "      <td>task</td>\n",
       "      <td>code</td>\n",
       "      <td>hmm</td>\n",
       "      <td>controller</td>\n",
       "      <td>face</td>\n",
       "      <td>complexity</td>\n",
       "      <td>optimal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term10</th>\n",
       "      <td>sound</td>\n",
       "      <td>pattern</td>\n",
       "      <td>location</td>\n",
       "      <td>nonlinear</td>\n",
       "      <td>pattern</td>\n",
       "      <td>capacity</td>\n",
       "      <td>feature</td>\n",
       "      <td>bayesian</td>\n",
       "      <td>activation</td>\n",
       "      <td>processor</td>\n",
       "      <td>letter</td>\n",
       "      <td>reinforcement_learning</td>\n",
       "      <td>structure</td>\n",
       "      <td>defined</td>\n",
       "      <td>variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term11</th>\n",
       "      <td>auditory</td>\n",
       "      <td>movement</td>\n",
       "      <td>local</td>\n",
       "      <td>optimal</td>\n",
       "      <td>connection</td>\n",
       "      <td>fixed_point</td>\n",
       "      <td>search</td>\n",
       "      <td>sample</td>\n",
       "      <td>trained</td>\n",
       "      <td>design</td>\n",
       "      <td>language</td>\n",
       "      <td>goal</td>\n",
       "      <td>view</td>\n",
       "      <td>proof</td>\n",
       "      <td>ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term12</th>\n",
       "      <td>temporal</td>\n",
       "      <td>stimulus</td>\n",
       "      <td>edge</td>\n",
       "      <td>optimization</td>\n",
       "      <td>synapsis</td>\n",
       "      <td>correlation</td>\n",
       "      <td>table</td>\n",
       "      <td>estimation</td>\n",
       "      <td>back_propagation</td>\n",
       "      <td>operation</td>\n",
       "      <td>frame</td>\n",
       "      <td>robot</td>\n",
       "      <td>clustering</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term13</th>\n",
       "      <td>correlation</td>\n",
       "      <td>position</td>\n",
       "      <td>spatial</td>\n",
       "      <td>iteration</td>\n",
       "      <td>et_al</td>\n",
       "      <td>hopfield</td>\n",
       "      <td>technique</td>\n",
       "      <td>component</td>\n",
       "      <td>hidden_layer</td>\n",
       "      <td>element</td>\n",
       "      <td>string</td>\n",
       "      <td>optimal</td>\n",
       "      <td>recognition</td>\n",
       "      <td>loss</td>\n",
       "      <td>curve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term14</th>\n",
       "      <td>ica</td>\n",
       "      <td>module</td>\n",
       "      <td>center</td>\n",
       "      <td>eq</td>\n",
       "      <td>neural</td>\n",
       "      <td>fig</td>\n",
       "      <td>experiment</td>\n",
       "      <td>likelihood</td>\n",
       "      <td>learn</td>\n",
       "      <td>parallel</td>\n",
       "      <td>symbol</td>\n",
       "      <td>current</td>\n",
       "      <td>part</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>effect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term15</th>\n",
       "      <td>response</td>\n",
       "      <td>visual</td>\n",
       "      <td>position</td>\n",
       "      <td>update</td>\n",
       "      <td>effect</td>\n",
       "      <td>behavior</td>\n",
       "      <td>rbf</td>\n",
       "      <td>log</td>\n",
       "      <td>connection</td>\n",
       "      <td>neural</td>\n",
       "      <td>speaker</td>\n",
       "      <td>reward</td>\n",
       "      <td>dimension</td>\n",
       "      <td>hypothesis</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term16</th>\n",
       "      <td>rate</td>\n",
       "      <td>location</td>\n",
       "      <td>velocity</td>\n",
       "      <td>constant</td>\n",
       "      <td>cortex</td>\n",
       "      <td>stable</td>\n",
       "      <td>expert</td>\n",
       "      <td>em</td>\n",
       "      <td>hidden</td>\n",
       "      <td>computation</td>\n",
       "      <td>recurrent</td>\n",
       "      <td>move</td>\n",
       "      <td>mapping</td>\n",
       "      <td>kernel</td>\n",
       "      <td>expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term17</th>\n",
       "      <td>phase</td>\n",
       "      <td>development</td>\n",
       "      <td>object</td>\n",
       "      <td>minimum</td>\n",
       "      <td>current</td>\n",
       "      <td>theory</td>\n",
       "      <td>training_set</td>\n",
       "      <td>step</td>\n",
       "      <td>generalization</td>\n",
       "      <td>device</td>\n",
       "      <td>trained</td>\n",
       "      <td>learned</td>\n",
       "      <td>similarity</td>\n",
       "      <td>assume</td>\n",
       "      <td>generalization_error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term18</th>\n",
       "      <td>amplitude</td>\n",
       "      <td>brain</td>\n",
       "      <td>surface</td>\n",
       "      <td>energy</td>\n",
       "      <td>threshold</td>\n",
       "      <td>delay</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>variance</td>\n",
       "      <td>backpropagation</td>\n",
       "      <td>digital</td>\n",
       "      <td>speech_recognition</td>\n",
       "      <td>trial</td>\n",
       "      <td>dimensional</td>\n",
       "      <td>definition</td>\n",
       "      <td>generalization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term19</th>\n",
       "      <td>coding</td>\n",
       "      <td>response</td>\n",
       "      <td>response</td>\n",
       "      <td>line</td>\n",
       "      <td>neuronal</td>\n",
       "      <td>noise</td>\n",
       "      <td>machine</td>\n",
       "      <td>entropy</td>\n",
       "      <td>connectionist</td>\n",
       "      <td>architecture</td>\n",
       "      <td>phoneme</td>\n",
       "      <td>path</td>\n",
       "      <td>digit</td>\n",
       "      <td>concept</td>\n",
       "      <td>selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term20</th>\n",
       "      <td>change</td>\n",
       "      <td>cue</td>\n",
       "      <td>contour</td>\n",
       "      <td>gradient_descent</td>\n",
       "      <td>layer</td>\n",
       "      <td>connection</td>\n",
       "      <td>application</td>\n",
       "      <td>posterior</td>\n",
       "      <td>step</td>\n",
       "      <td>implemented</td>\n",
       "      <td>experiment</td>\n",
       "      <td>td</td>\n",
       "      <td>pca</td>\n",
       "      <td>xi</td>\n",
       "      <td>size</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Topic 1         Topic 2  ...       Topic 14              Topic 15\n",
       "Term1        signal             map  ...          bound              training\n",
       "Term2         noise        activity  ...        theorem            prediction\n",
       "Term3        source          target  ...          class                 noise\n",
       "Term4     frequency  representation  ...           size               average\n",
       "Term5        filter           human  ...         theory          training_set\n",
       "Term6       channel         subject  ...    probability                  test\n",
       "Term7     component             eye  ...  approximation              estimate\n",
       "Term8    adaptation           motor  ...      threshold            regression\n",
       "Term9     detection       structure  ...     complexity               optimal\n",
       "Term10        sound         pattern  ...        defined              variance\n",
       "Term11     auditory        movement  ...          proof              ensemble\n",
       "Term12     temporal        stimulus  ...         linear                linear\n",
       "Term13  correlation        position  ...           loss                 curve\n",
       "Term14          ica          module  ...     polynomial                effect\n",
       "Term15     response          visual  ...     hypothesis                  bias\n",
       "Term16         rate        location  ...         kernel              expected\n",
       "Term17        phase     development  ...         assume  generalization_error\n",
       "Term18    amplitude           brain  ...     definition        generalization\n",
       "Term19       coding        response  ...        concept             selection\n",
       "Term20       change             cue  ...             xi                  size\n",
       "\n",
       "[20 rows x 15 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df = pd.DataFrame([[term for term, wt in topic] \n",
    "                              for topic in topics], \n",
    "                         columns = ['Term'+str(i) for i in range(1, 21)],\n",
    "                         index=['Topic '+str(t) for t in range(1, best_lda_model.num_topics+1)]).T\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "id": "MvyOKlu4p7UG",
    "outputId": "ae3a1693-6110-4e26-9364-224d56ab813a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Terms per Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>signal, noise, source, frequency, filter, channel, component, adaptation, detection, sound, auditory, temporal, correlation, ica, response, rate, phase, amplitude, coding, change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic2</th>\n",
       "      <td>map, activity, target, representation, human, subject, eye, motor, structure, pattern, movement, stimulus, position, module, visual, location, development, brain, response, cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic3</th>\n",
       "      <td>image, motion, visual, direction, region, field, orientation, pixel, receptive_field, location, local, edge, spatial, center, position, velocity, object, surface, response, contour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic4</th>\n",
       "      <td>vector, matrix, solution, equation, convergence, linear, gradient, constraint, rate, nonlinear, optimal, optimization, iteration, eq, update, constant, minimum, energy, line, gradient_descent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic5</th>\n",
       "      <td>neuron, cell, response, stimulus, synaptic, spike, activity, firing, cortical, pattern, connection, synapsis, et_al, neural, effect, cortex, current, threshold, neuronal, layer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic6</th>\n",
       "      <td>dynamic, state, memory, pattern, neuron, equation, phase, recurrent, attractor, capacity, fixed_point, correlation, hopfield, fig, behavior, stable, theory, delay, noise, connection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic7</th>\n",
       "      <td>node, class, classification, classifier, training, tree, pattern, test, sample, feature, search, table, technique, experiment, rbf, expert, training_set, accuracy, machine, application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic8</th>\n",
       "      <td>distribution, probability, gaussian, variable, prior, density, estimate, mixture, approximation, bayesian, sample, estimation, component, likelihood, log, em, step, variance, entropy, posterior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic9</th>\n",
       "      <td>unit, layer, net, hidden_unit, training, rule, pattern, architecture, task, activation, trained, back_propagation, hidden_layer, learn, connection, hidden, generalization, backpropagation, connectionist, step</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic10</th>\n",
       "      <td>circuit, chip, current, bit, analog, neuron, voltage, implementation, code, processor, design, operation, element, parallel, neural, computation, device, digital, architecture, implemented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic11</th>\n",
       "      <td>word, sequence, recognition, training, state, context, speech, character, hmm, letter, language, frame, string, symbol, speaker, recurrent, trained, speech_recognition, phoneme, experiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic12</th>\n",
       "      <td>state, control, action, step, policy, task, trajectory, environment, controller, reinforcement_learning, goal, robot, optimal, current, reward, move, learned, trial, path, td</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic13</th>\n",
       "      <td>feature, image, vector, representation, object, cluster, distance, transformation, face, structure, view, clustering, recognition, part, dimension, mapping, similarity, dimensional, digit, pca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic14</th>\n",
       "      <td>bound, theorem, class, size, theory, probability, approximation, threshold, complexity, defined, proof, linear, loss, polynomial, hypothesis, kernel, assume, definition, concept, xi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic15</th>\n",
       "      <td>training, prediction, noise, average, training_set, test, estimate, regression, optimal, variance, ensemble, linear, curve, effect, bias, expected, generalization_error, generalization, selection, size</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                          Terms per Topic\n",
       "Topic1   signal, noise, source, frequency, filter, channel, component, adaptation, detection, sound, auditory, temporal, correlation, ica, response, rate, phase, amplitude, coding, change                              \n",
       "Topic2   map, activity, target, representation, human, subject, eye, motor, structure, pattern, movement, stimulus, position, module, visual, location, development, brain, response, cue                                \n",
       "Topic3   image, motion, visual, direction, region, field, orientation, pixel, receptive_field, location, local, edge, spatial, center, position, velocity, object, surface, response, contour                            \n",
       "Topic4   vector, matrix, solution, equation, convergence, linear, gradient, constraint, rate, nonlinear, optimal, optimization, iteration, eq, update, constant, minimum, energy, line, gradient_descent                 \n",
       "Topic5   neuron, cell, response, stimulus, synaptic, spike, activity, firing, cortical, pattern, connection, synapsis, et_al, neural, effect, cortex, current, threshold, neuronal, layer                                \n",
       "Topic6   dynamic, state, memory, pattern, neuron, equation, phase, recurrent, attractor, capacity, fixed_point, correlation, hopfield, fig, behavior, stable, theory, delay, noise, connection                           \n",
       "Topic7   node, class, classification, classifier, training, tree, pattern, test, sample, feature, search, table, technique, experiment, rbf, expert, training_set, accuracy, machine, application                        \n",
       "Topic8   distribution, probability, gaussian, variable, prior, density, estimate, mixture, approximation, bayesian, sample, estimation, component, likelihood, log, em, step, variance, entropy, posterior               \n",
       "Topic9   unit, layer, net, hidden_unit, training, rule, pattern, architecture, task, activation, trained, back_propagation, hidden_layer, learn, connection, hidden, generalization, backpropagation, connectionist, step\n",
       "Topic10  circuit, chip, current, bit, analog, neuron, voltage, implementation, code, processor, design, operation, element, parallel, neural, computation, device, digital, architecture, implemented                    \n",
       "Topic11  word, sequence, recognition, training, state, context, speech, character, hmm, letter, language, frame, string, symbol, speaker, recurrent, trained, speech_recognition, phoneme, experiment                    \n",
       "Topic12  state, control, action, step, policy, task, trajectory, environment, controller, reinforcement_learning, goal, robot, optimal, current, reward, move, learned, trial, path, td                                  \n",
       "Topic13  feature, image, vector, representation, object, cluster, distance, transformation, face, structure, view, clustering, recognition, part, dimension, mapping, similarity, dimensional, digit, pca                \n",
       "Topic14  bound, theorem, class, size, theory, probability, approximation, threshold, complexity, defined, proof, linear, loss, polynomial, hypothesis, kernel, assume, definition, concept, xi                           \n",
       "Topic15  training, prediction, noise, average, training_set, test, estimate, regression, optimal, variance, ensemble, linear, curve, effect, bias, expected, generalization_error, generalization, selection, size       "
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "topics_df = pd.DataFrame([', '.join([term for term, wt in topic])  \n",
    "                              for topic in topics],\n",
    "                         columns = ['Terms per Topic'],\n",
    "                         index=['Topic'+str(t) for t in range(1, best_lda_model.num_topics+1)]\n",
    "                         )\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SrveLQ5e12cP"
   },
   "source": [
    "# Interpreting Topic Model Results\n",
    "\n",
    "An interesting point to remember is, given a corpus of documents (in the form of\n",
    "features, e.g., Bag of Words) and a trained topic model, you can predict the distribution of\n",
    "topics in each document (research paper in this case).\n",
    "\n",
    "We can now get the most dominant topic per research paper with some intelligent\n",
    "sorting and indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "bXv0NRCXum-I",
    "outputId": "f7f3f272-e7b2-4b11-d0d6-1825ebef4e6a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "tm_results = best_lda_model[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "WjEHWhVGuuG5",
    "outputId": "78a75797-835f-4b0a-ee75-66e04109714d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 0.41996464028287767),\n",
       " (4, 0.5856681949397182),\n",
       " (5, 0.19490434142752022),\n",
       " (9, 0.5570885822835433),\n",
       " (4, 0.31967670011148275)]"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_topics = [sorted(topics, key=lambda record: -record[1])[0] \n",
    "                     for topics in tm_results]\n",
    "corpus_topics[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GFmddPmQuyXS"
   },
   "outputs": [],
   "source": [
    "corpus_topic_df = pd.DataFrame()\n",
    "corpus_topic_df['Document'] = range(0, len(papers))\n",
    "corpus_topic_df['Dominant Topic'] = [item[0]+1 for item in corpus_topics]\n",
    "corpus_topic_df['Contribution %'] = [round(item[1]*100, 2) for item in corpus_topics]\n",
    "corpus_topic_df['Topic Desc'] = [topics_df.iloc[t[0]]['Terms per Topic'] for t in corpus_topics]\n",
    "corpus_topic_df['Paper'] = papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U_nNj9_t12cb"
   },
   "source": [
    "# Dominant Topics in Specific Research Papers\n",
    "\n",
    "Another interesting perspective is to select specific papers, view the most dominant topic\n",
    "in each of those papers, and see if that makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "pN45exiiu5sx",
    "outputId": "ed203427-7455-472c-a0b5-24041f0de050"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Dominant Topic</th>\n",
       "      <th>Contribution %</th>\n",
       "      <th>Topic Desc</th>\n",
       "      <th>Paper</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dominant Topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1288</td>\n",
       "      <td>1</td>\n",
       "      <td>61.78</td>\n",
       "      <td>signal, noise, source, frequency, filter, channel, component, adaptation, detection, sound, auditory, temporal, correlation, ica, response, rate, phase, amplitude, coding, change</td>\n",
       "      <td>Extended ICA Removes Artifacts from \\nElectroencephalographic Recordings \\nTzyy-Ping Jung , Colin Humphries , Te-Won Lee , Scott Makeig 2'3, \\nMartin J. McKeown , Vicente Iragui 3, Terrence J....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>416</td>\n",
       "      <td>2</td>\n",
       "      <td>65.52</td>\n",
       "      <td>map, activity, target, representation, human, subject, eye, motor, structure, pattern, movement, stimulus, position, module, visual, location, development, brain, response, cue</td>\n",
       "      <td>Further Studies of a Model for the \\nDevelopment and Regeneration \\nof Eye-Brain Maps \\nJ.D. Cowan &amp; A.E. Friedman \\nDepartment of Mathematics, Committee on \\nNeurobiology, and Brain Research Inst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>60.64</td>\n",
       "      <td>image, motion, visual, direction, region, field, orientation, pixel, receptive_field, location, local, edge, spatial, center, position, velocity, object, surface, response, contour</td>\n",
       "      <td>A \\nNeural Network Model of 3-D \\nLightness Perception \\nLuiz Pessoa \\nFederal Univ. of Rio de Janeiro \\nRio de Janeiro, RJ, Brazil \\npessoa@cos.ufrj.br \\nWilliam D. Ross \\nBoston University \\nBos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1272</td>\n",
       "      <td>4</td>\n",
       "      <td>62.44</td>\n",
       "      <td>vector, matrix, solution, equation, convergence, linear, gradient, constraint, rate, nonlinear, optimal, optimization, iteration, eq, update, constant, minimum, energy, line, gradient_descent</td>\n",
       "      <td>A Convergence Proof for the Softassign \\nQuadratic Assignment Algorithm \\nAnand Rangarajan \\nDepartment of Diagnostic Radiology \\nYale University School of Medicine \\nNew Haven, CT 06520-8042 \\ne-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>571</td>\n",
       "      <td>5</td>\n",
       "      <td>77.11</td>\n",
       "      <td>neuron, cell, response, stimulus, synaptic, spike, activity, firing, cortical, pattern, connection, synapsis, et_al, neural, effect, cortex, current, threshold, neuronal, layer</td>\n",
       "      <td>Network activity determines \\nspatio-temporal integration in single cells \\njvind Bernander, Christof Koch * \\nComputation and Neural Systems Program, \\nCalifornia Institute of Technology, \\nPasa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>180</td>\n",
       "      <td>6</td>\n",
       "      <td>67.99</td>\n",
       "      <td>dynamic, state, memory, pattern, neuron, equation, phase, recurrent, attractor, capacity, fixed_point, correlation, hopfield, fig, behavior, stable, theory, delay, noise, connection</td>\n",
       "      <td>568 \\nDYNAMICS OF ANALOG NEURAL \\nNETWORKS WITH TIME DELAY \\nC.M. Marcus and R.M. Westervelt \\nDivision of Applied Sciences and Department of Physics \\nHarvard University, Cambridge Massachusetts ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>314</td>\n",
       "      <td>7</td>\n",
       "      <td>70.68</td>\n",
       "      <td>node, class, classification, classifier, training, tree, pattern, test, sample, feature, search, table, technique, experiment, rbf, expert, training_set, accuracy, machine, application</td>\n",
       "      <td>A Comparative Study of the Practical \\nCharacteristics of Neural Network and \\nConventional Pattern Classifiers \\nKenney Ng \\nBBN Systems and Technologies \\nCambridge, MA 02138 \\nAbstract \\nRichar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1607</td>\n",
       "      <td>8</td>\n",
       "      <td>64.08</td>\n",
       "      <td>distribution, probability, gaussian, variable, prior, density, estimate, mixture, approximation, bayesian, sample, estimation, component, likelihood, log, em, step, variance, entropy, posterior</td>\n",
       "      <td>The Infinite Gaussian Mixture Model \\nCarl Edward Rasmussen \\nDepartment of Mathematical Modelling \\nTechnical University of Denmark \\nBuilding 321, DK-2800 Kongens Lyngby, Denmark \\ncarl@imm.dtu....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>776</td>\n",
       "      <td>9</td>\n",
       "      <td>66.23</td>\n",
       "      <td>unit, layer, net, hidden_unit, training, rule, pattern, architecture, task, activation, trained, back_propagation, hidden_layer, learn, connection, hidden, generalization, backpropagation, connect...</td>\n",
       "      <td>Analyzing Cross Connected Networks \\nThomas R. Shultz \\nDepartment of Psychology &amp; \\nMcGill Cognitive Science Centre \\nMcGill University \\nMontr6al, Qu6bec, Canada H3A lB 1 \\nsh ultz@ psych. mcgil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>962</td>\n",
       "      <td>10</td>\n",
       "      <td>69.13</td>\n",
       "      <td>circuit, chip, current, bit, analog, neuron, voltage, implementation, code, processor, design, operation, element, parallel, neural, computation, device, digital, architecture, implemented</td>\n",
       "      <td>Single Transistor Learning Synapses \\nPaul Hasler, Chris Diorio, Bradley A. Minch, Carver Mead \\nCalifornia Institute of Technology \\nPasadena, CA 91125 \\n(SlS) 95- 2S12 \\npaul@hobiecat.pcmp.calt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>682</td>\n",
       "      <td>11</td>\n",
       "      <td>71.41</td>\n",
       "      <td>word, sequence, recognition, training, state, context, speech, character, hmm, letter, language, frame, string, symbol, speaker, recurrent, trained, speech_recognition, phoneme, experiment</td>\n",
       "      <td>Connected Letter Recognition with a \\nMulti-State Time Delay Neural Network \\nHermann Hild and Alex Waibel \\nSchool of Computer Science \\nCarnegie Mellon University \\nPittsburgh, PA 15213-3891, US...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1576</td>\n",
       "      <td>12</td>\n",
       "      <td>78.10</td>\n",
       "      <td>state, control, action, step, policy, task, trajectory, environment, controller, reinforcement_learning, goal, robot, optimal, current, reward, move, learned, trial, path, td</td>\n",
       "      <td>The effect of eligibility traces on finding optimal memoryless \\npolicies in partially observable Markov decision processes \\nJohn Loch \\nDepartment of Computer Science \\nUniversity of Colorado \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1437</td>\n",
       "      <td>13</td>\n",
       "      <td>60.21</td>\n",
       "      <td>feature, image, vector, representation, object, cluster, distance, transformation, face, structure, view, clustering, recognition, part, dimension, mapping, similarity, dimensional, digit, pca</td>\n",
       "      <td>Mapping a manifold of perceptual observations \\nJoshua B. Tenenbaum \\nDepartment of Brain and Cognitive Sciences \\nMassachusetts Institute of Technology, Cambridge, MA 02139 \\nj bt @psyche. mi t. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>527</td>\n",
       "      <td>14</td>\n",
       "      <td>82.70</td>\n",
       "      <td>bound, theorem, class, size, theory, probability, approximation, threshold, complexity, defined, proof, linear, loss, polynomial, hypothesis, kernel, assume, definition, concept, xi</td>\n",
       "      <td>Polynomial Uniform Convergence of \\nRelative Frequencies to Probabilities \\nAlberto Bertoni, Paola Campadelll;' Anna Morpurgo, Sandra Panlzza \\nDipartimento di Scienze dell'Informazione \\nUniversi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1035</td>\n",
       "      <td>15</td>\n",
       "      <td>75.07</td>\n",
       "      <td>training, prediction, noise, average, training_set, test, estimate, regression, optimal, variance, ensemble, linear, curve, effect, bias, expected, generalization_error, generalization, selection,...</td>\n",
       "      <td>Learning with ensembles: How \\nover-fitting can be useful \\nPeter Sollich \\nDepartment of Physics \\nUniversity of Edinburgh, U.K. \\nP. Solliched. ac.uk \\nAnders Krogh* \\nNORDITA, Blegdamsvej 17 \\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Document  ...                                                                                                                                                                                                    Paper\n",
       "Dominant Topic            ...                                                                                                                                                                                                         \n",
       "1                   1288  ...  Extended ICA Removes Artifacts from \\nElectroencephalographic Recordings \\nTzyy-Ping Jung , Colin Humphries , Te-Won Lee , Scott Makeig 2'3, \\nMartin J. McKeown , Vicente Iragui 3, Terrence J....\n",
       "2                    416  ...  Further Studies of a Model for the \\nDevelopment and Regeneration \\nof Eye-Brain Maps \\nJ.D. Cowan & A.E. Friedman \\nDepartment of Mathematics, Committee on \\nNeurobiology, and Brain Research Inst...\n",
       "3                   1100  ...  A \\nNeural Network Model of 3-D \\nLightness Perception \\nLuiz Pessoa \\nFederal Univ. of Rio de Janeiro \\nRio de Janeiro, RJ, Brazil \\npessoa@cos.ufrj.br \\nWilliam D. Ross \\nBoston University \\nBos...\n",
       "4                   1272  ...  A Convergence Proof for the Softassign \\nQuadratic Assignment Algorithm \\nAnand Rangarajan \\nDepartment of Diagnostic Radiology \\nYale University School of Medicine \\nNew Haven, CT 06520-8042 \\ne-...\n",
       "5                    571  ...  Network activity determines \\nspatio-temporal integration in single cells \\njvind Bernander, Christof Koch * \\nComputation and Neural Systems Program, \\nCalifornia Institute of Technology, \\nPasa...\n",
       "6                    180  ...  568 \\nDYNAMICS OF ANALOG NEURAL \\nNETWORKS WITH TIME DELAY \\nC.M. Marcus and R.M. Westervelt \\nDivision of Applied Sciences and Department of Physics \\nHarvard University, Cambridge Massachusetts ...\n",
       "7                    314  ...  A Comparative Study of the Practical \\nCharacteristics of Neural Network and \\nConventional Pattern Classifiers \\nKenney Ng \\nBBN Systems and Technologies \\nCambridge, MA 02138 \\nAbstract \\nRichar...\n",
       "8                   1607  ...  The Infinite Gaussian Mixture Model \\nCarl Edward Rasmussen \\nDepartment of Mathematical Modelling \\nTechnical University of Denmark \\nBuilding 321, DK-2800 Kongens Lyngby, Denmark \\ncarl@imm.dtu....\n",
       "9                    776  ...  Analyzing Cross Connected Networks \\nThomas R. Shultz \\nDepartment of Psychology & \\nMcGill Cognitive Science Centre \\nMcGill University \\nMontr6al, Qu6bec, Canada H3A lB 1 \\nsh ultz@ psych. mcgil...\n",
       "10                   962  ...  Single Transistor Learning Synapses \\nPaul Hasler, Chris Diorio, Bradley A. Minch, Carver Mead \\nCalifornia Institute of Technology \\nPasadena, CA 91125 \\n(SlS) 95- 2S12 \\npaul@hobiecat.pcmp.calt...\n",
       "11                   682  ...  Connected Letter Recognition with a \\nMulti-State Time Delay Neural Network \\nHermann Hild and Alex Waibel \\nSchool of Computer Science \\nCarnegie Mellon University \\nPittsburgh, PA 15213-3891, US...\n",
       "12                  1576  ...  The effect of eligibility traces on finding optimal memoryless \\npolicies in partially observable Markov decision processes \\nJohn Loch \\nDepartment of Computer Science \\nUniversity of Colorado \\n...\n",
       "13                  1437  ...  Mapping a manifold of perceptual observations \\nJoshua B. Tenenbaum \\nDepartment of Brain and Cognitive Sciences \\nMassachusetts Institute of Technology, Cambridge, MA 02139 \\nj bt @psyche. mi t. ...\n",
       "14                   527  ...  Polynomial Uniform Convergence of \\nRelative Frequencies to Probabilities \\nAlberto Bertoni, Paola Campadelll;' Anna Morpurgo, Sandra Panlzza \\nDipartimento di Scienze dell'Informazione \\nUniversi...\n",
       "15                  1035  ...  Learning with ensembles: How \\nover-fitting can be useful \\nPeter Sollich \\nDepartment of Physics \\nUniversity of Edinburgh, U.K. \\nP. Solliched. ac.uk \\nAnders Krogh* \\nNORDITA, Blegdamsvej 17 \\...\n",
       "\n",
       "[15 rows x 5 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_topic_df.groupby('Dominant Topic').apply(lambda topic_set: (topic_set.sort_values(by=['Contribution %'], \n",
    "                                                                                         ascending=False)\n",
    "                                                                             .iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "I0QF6K53v4zN",
    "outputId": "b31f5260-5d30-4aaa-8139-d58304e7b887"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[661, 716, 504]"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_paper_patterns = ['Feudal Reinforcement Learning \\nPeter', 'Illumination-Invariant Face Recognition with a', 'Improved Hidden Markov Model Speech Recognition']\n",
    "sample_paper_idxs = [idx for pattern in sample_paper_patterns \n",
    "                            for idx, content in enumerate(papers) \n",
    "                                if pattern in content]\n",
    "sample_paper_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "colab_type": "code",
    "id": "d7JrXUbsw0bt",
    "outputId": "ab58c8b9-7a7d-4555-a000-c4bc4d00287f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Dominant Topic</th>\n",
       "      <th>Contribution %</th>\n",
       "      <th>Topic Desc</th>\n",
       "      <th>Paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>504</td>\n",
       "      <td>11</td>\n",
       "      <td>42.33</td>\n",
       "      <td>word, sequence, recognition, training, state, context, speech, character, hmm, letter, language, frame, string, symbol, speaker, recurrent, trained, speech_recognition, phoneme, experiment</td>\n",
       "      <td>Improved Hidden Markov Model \\nSpeech Recognition Using \\nRadial Basis Function Networks \\nElliot Singer and Richard P. Lippmann \\nLincoln Laboratory, MIT \\nLexington, MA 02173-9108, USA \\nAbstrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>661</td>\n",
       "      <td>12</td>\n",
       "      <td>58.21</td>\n",
       "      <td>state, control, action, step, policy, task, trajectory, environment, controller, reinforcement_learning, goal, robot, optimal, current, reward, move, learned, trial, path, td</td>\n",
       "      <td>Feudal Reinforcement Learning \\nPeter Dayan \\nCNL \\nThe Salk Institute \\nPO Box 85800 \\nSan Diego CA 92186-5800, USA \\ndayanhelmholtz. sdsc. edu \\nGeoffrey E Hinton \\nDepartment of Computer Scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>716</td>\n",
       "      <td>13</td>\n",
       "      <td>37.79</td>\n",
       "      <td>feature, image, vector, representation, object, cluster, distance, transformation, face, structure, view, clustering, recognition, part, dimension, mapping, similarity, dimensional, digit, pca</td>\n",
       "      <td>Illumination-Invariant Face Recognition with a \\nContrast Sensitive Silicon Retina \\nJoachim M. Buhmann \\nRheinische Friedrich-Wilhelms-Universitfit \\nInstitut ftir Informatik II, R6merstrage 164 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Document  ...                                                                                                                                                                                                    Paper\n",
       "504       504  ...  Improved Hidden Markov Model \\nSpeech Recognition Using \\nRadial Basis Function Networks \\nElliot Singer and Richard P. Lippmann \\nLincoln Laboratory, MIT \\nLexington, MA 02173-9108, USA \\nAbstrac...\n",
       "661       661  ...  Feudal Reinforcement Learning \\nPeter Dayan \\nCNL \\nThe Salk Institute \\nPO Box 85800 \\nSan Diego CA 92186-5800, USA \\ndayanhelmholtz. sdsc. edu \\nGeoffrey E Hinton \\nDepartment of Computer Scien...\n",
       "716       716  ...  Illumination-Invariant Face Recognition with a \\nContrast Sensitive Silicon Retina \\nJoachim M. Buhmann \\nRheinische Friedrich-Wilhelms-Universitfit \\nInstitut ftir Informatik II, R6merstrage 164 ...\n",
       "\n",
       "[3 rows x 5 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 200)\n",
    "(corpus_topic_df[corpus_topic_df['Document']\n",
    "                 .isin(sample_paper_idxs)])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "07-NLP Applications - Topic Modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
