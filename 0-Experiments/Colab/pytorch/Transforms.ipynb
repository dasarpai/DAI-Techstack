{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Transforms.ipynb","provenance":[{"file_id":"1-PZU7a4gzdN0hHOniG_sKEx0M12csyVl","timestamp":1615615928895}],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"YvA5iwv_6yyV"},"source":["\r\n","\r\n","'''\r\n","Transforms can be applied to PIL images, tensors, ndarrays, or custom data\r\n","during creation of the DataSet\r\n","complete list of built-in transforms: \r\n","https://pytorch.org/docs/stable/torchvision/transforms.html\r\n","On Images\r\n","---------\r\n","CenterCrop, Grayscale, Pad, RandomAffine\r\n","RandomCrop, RandomHorizontalFlip, RandomRotation\r\n","Resize, Scale\r\n","On Tensors\r\n","----------\r\n","LinearTransformation, Normalize, RandomErasing\r\n","Conversion\r\n","----------\r\n","ToPILImage: from tensor or ndrarray\r\n","ToTensor : from numpy.ndarray or PILImage\r\n","Generic\r\n","-------\r\n","Use Lambda \r\n","Custom\r\n","------\r\n","Write own class\r\n","Compose multiple Transforms\r\n","---------------------------\r\n","composed = transforms.Compose([Rescale(256),\r\n","                               RandomCrop(224)])\r\n","'''\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"2GWyAXDd6qvG","executionInfo":{"status":"ok","timestamp":1615616227318,"user_tz":-330,"elapsed":4917,"user":{"displayName":"Hari Thapliyaal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghe9hJnok_MYMV4Ol_O45RoplvJrRkuikXSvQWNtg=s64","userId":"09088303666341280217"}}},"source":["import torch\r\n","import torchvision\r\n","from torch.utils.data import Dataset\r\n","import numpy as np"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"gkLleZqS63hz","executionInfo":{"status":"ok","timestamp":1615616275880,"user_tz":-330,"elapsed":1330,"user":{"displayName":"Hari Thapliyaal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghe9hJnok_MYMV4Ol_O45RoplvJrRkuikXSvQWNtg=s64","userId":"09088303666341280217"}}},"source":["class WineDataset(Dataset):\r\n","\r\n","    def __init__(self, transform=None):\r\n","        #xy = np.loadtxt('./data/wine/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\r\n","        xy = np.loadtxt('wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\r\n","        self.n_samples = xy.shape[0]\r\n","\r\n","        # note that we do not convert to tensor here\r\n","        self.x_data = xy[:, 1:]\r\n","        self.y_data = xy[:, [0]]\r\n","\r\n","        self.transform = transform\r\n","\r\n","    def __getitem__(self, index):\r\n","        sample = self.x_data[index], self.y_data[index]\r\n","\r\n","        if self.transform:\r\n","            sample = self.transform(sample)\r\n","\r\n","        return sample\r\n","\r\n","    def __len__(self):\r\n","        return self.n_samples"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"rU2EazO766bB","executionInfo":{"status":"ok","timestamp":1615616233600,"user_tz":-330,"elapsed":1472,"user":{"displayName":"Hari Thapliyaal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghe9hJnok_MYMV4Ol_O45RoplvJrRkuikXSvQWNtg=s64","userId":"09088303666341280217"}}},"source":["# Custom Transforms\r\n","# implement __call__(self, sample)\r\n","class ToTensor:\r\n","    # Convert ndarrays to Tensors\r\n","    def __call__(self, sample):\r\n","        inputs, targets = sample\r\n","        return torch.from_numpy(inputs), torch.from_numpy(targets)\r\n","\r\n","class MulTransform:\r\n","    # multiply inputs with a given factor\r\n","    def __init__(self, factor):\r\n","        self.factor = factor\r\n","\r\n","    def __call__(self, sample):\r\n","        inputs, targets = sample\r\n","        inputs *= self.factor\r\n","        return inputs, targets"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"-9f64pXq694R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615616286923,"user_tz":-330,"elapsed":1395,"user":{"displayName":"Hari Thapliyaal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghe9hJnok_MYMV4Ol_O45RoplvJrRkuikXSvQWNtg=s64","userId":"09088303666341280217"}},"outputId":"d3a9c911-9563-4e6c-c94a-9324ddf63948"},"source":["print('Without Transform')\r\n","dataset = WineDataset()\r\n","first_data = dataset[0]\r\n","features, labels = first_data\r\n","print(type(features), type(labels))\r\n","print(features, labels)\r\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Without Transform\n","<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n","[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n"," 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03] [1.]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d3jfARQc7CJq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615616291454,"user_tz":-330,"elapsed":1254,"user":{"displayName":"Hari Thapliyaal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghe9hJnok_MYMV4Ol_O45RoplvJrRkuikXSvQWNtg=s64","userId":"09088303666341280217"}},"outputId":"5b29882b-2028-468e-eea5-b3ddc9102a10"},"source":["print('\\nWith Tensor Transform')\r\n","dataset = WineDataset(transform=ToTensor())\r\n","first_data = dataset[0]\r\n","features, labels = first_data\r\n","print(type(features), type(labels))\r\n","print(features, labels)\r\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["\n","With Tensor Transform\n","<class 'torch.Tensor'> <class 'torch.Tensor'>\n","tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n","        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n","        1.0650e+03]) tensor([1.])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AZAe5tVs7Dya","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615616786580,"user_tz":-330,"elapsed":1323,"user":{"displayName":"Hari Thapliyaal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghe9hJnok_MYMV4Ol_O45RoplvJrRkuikXSvQWNtg=s64","userId":"09088303666341280217"}},"outputId":"f390cc85-f79c-4606-f68d-7cf057fddc9b"},"source":["print('\\nWith Tensor and Multiplication Transform')\r\n","composed = torchvision.transforms.Compose([ToTensor(), MulTransform(4)])\r\n","dataset = WineDataset(transform=composed)\r\n","first_data = dataset[0]\r\n","features, labels = first_data\r\n","print(type(features), type(labels))\r\n","print(features, labels)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["\n","With Tensor and Multiplication Transform\n","<class 'torch.Tensor'> <class 'torch.Tensor'>\n","tensor([5.6920e+01, 6.8400e+00, 9.7200e+00, 6.2400e+01, 5.0800e+02, 1.1200e+01,\n","        1.2240e+01, 1.1200e+00, 9.1600e+00, 2.2560e+01, 4.1600e+00, 1.5680e+01,\n","        4.2600e+03]) tensor([1.])\n"],"name":"stdout"}]}]}